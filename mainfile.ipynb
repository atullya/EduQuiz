{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9734cf3f-aef1-4c05-a0f0-2a1f7acee9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1873f8bf-0fd6-4aaa-a8d4-cce6cbb64824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458690c4-1249-458d-86df-26a00b6ccb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCQGenerator:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Question patterns for different types\n",
    "        self.question_patterns = {\n",
    "            'what': ['What is {}?', 'What does {} mean?', 'What refers to {}?'],\n",
    "            'who': ['Who is {}?', 'Who was {}?'],\n",
    "            'when': ['When did {} occur?', 'When was {} established?'],\n",
    "            'where': ['Where is {} located?', 'Where does {} take place?'],\n",
    "            'why': ['Why is {} important?', 'Why does {} happen?'],\n",
    "            'how': ['How does {} work?', 'How is {} defined?']\n",
    "        }\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess the input text\"\"\"\n",
    "        # Remove extra whitespace and normalize\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        \n",
    "        # Remove special characters but keep sentence structure\n",
    "        text = re.sub(r'[^\\w\\s\\.\\!\\?\\,\\;\\:]', '', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def extract_sentences(self, text):\n",
    "        \"\"\"Extract and clean sentences from text\"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        # Filter out very short sentences\n",
    "        sentences = [s for s in sentences if len(s.split()) > 5]\n",
    "        \n",
    "        return sentences\n",
    "    \n",
    "    def extract_keywords(self, text, top_n=20):\n",
    "        \"\"\"Extract important keywords using TF-IDF from scratch\"\"\"\n",
    "        # Tokenize and clean\n",
    "        words = word_tokenize(text.lower())\n",
    "        words = [word for word in words if word.isalpha() and word not in self.stop_words]\n",
    "        words = [self.lemmatizer.lemmatize(word) for word in words]\n",
    "        \n",
    "        # Calculate term frequency\n",
    "        word_count = len(words)\n",
    "        tf = Counter(words)\n",
    "        \n",
    "        # Convert to TF scores\n",
    "        tf_scores = {word: count/word_count for word, count in tf.items()}\n",
    "        \n",
    "        # For IDF, we'll use sentence-based document frequency\n",
    "        sentences = self.extract_sentences(text)\n",
    "        doc_count = len(sentences)\n",
    "        \n",
    "        # Calculate document frequency for each word\n",
    "        df = defaultdict(int)\n",
    "        for sentence in sentences:\n",
    "            sentence_words = set(word_tokenize(sentence.lower()))\n",
    "            sentence_words = {word for word in sentence_words if word.isalpha() and word not in self.stop_words}\n",
    "            sentence_words = {self.lemmatizer.lemmatize(word) for word in sentence_words}\n",
    "            \n",
    "            for word in sentence_words:\n",
    "                df[word] += 1\n",
    "        \n",
    "        # Calculate TF-IDF scores\n",
    "        tfidf_scores = {}\n",
    "        for word in tf_scores:\n",
    "            if df[word] > 0:\n",
    "                idf = math.log(doc_count / df[word])\n",
    "                tfidf_scores[word] = tf_scores[word] * idf\n",
    "        \n",
    "        # Get top keywords\n",
    "        top_keywords = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        \n",
    "        return [word for word, score in top_keywords]\n",
    "    \n",
    "    def extract_named_entities(self, text):\n",
    "        \"\"\"Extract named entities using POS tagging\"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "        entities = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            pos_tags = pos_tag(words)\n",
    "            \n",
    "            # Extract proper nouns and noun phrases\n",
    "            current_entity = []\n",
    "            for word, tag in pos_tags:\n",
    "                if tag in ['NNP', 'NNPS']:  # Proper nouns\n",
    "                    current_entity.append(word)\n",
    "                elif tag in ['NN', 'NNS'] and current_entity:  # Regular nouns following proper nouns\n",
    "                    current_entity.append(word)\n",
    "                else:\n",
    "                    if current_entity and len(current_entity) >= 1:\n",
    "                        entities.append(' '.join(current_entity))\n",
    "                    current_entity = []\n",
    "            \n",
    "            # Don't forget the last entity\n",
    "            if current_entity and len(current_entity) >= 1:\n",
    "                entities.append(' '.join(current_entity))\n",
    "        \n",
    "        # Remove duplicates and filter\n",
    "        entities = list(set(entities))\n",
    "        entities = [e for e in entities if len(e.split()) <= 3 and len(e) > 2]\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    def calculate_cosine_similarity(self, text1, text2):\n",
    "        \"\"\"Calculate cosine similarity between two texts from scratch\"\"\"\n",
    "        # Tokenize and preprocess both texts\n",
    "        words1 = word_tokenize(text1.lower())\n",
    "        words2 = word_tokenize(text2.lower())\n",
    "        \n",
    "        words1 = [word for word in words1 if word.isalpha() and word not in self.stop_words]\n",
    "        words2 = [word for word in words2 if word.isalpha() and word not in self.stop_words]\n",
    "        \n",
    "        words1 = [self.lemmatizer.lemmatize(word) for word in words1]\n",
    "        words2 = [self.lemmatizer.lemmatize(word) for word in words2]\n",
    "        \n",
    "        # Create vocabulary\n",
    "        vocab = set(words1 + words2)\n",
    "        \n",
    "        if not vocab:\n",
    "            return 0.0\n",
    "        \n",
    "        # Create vectors\n",
    "        vec1 = [words1.count(word) for word in vocab]\n",
    "        vec2 = [words2.count(word) for word in vocab]\n",
    "        \n",
    "        # Calculate dot product\n",
    "        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "        \n",
    "        # Calculate magnitudes\n",
    "        magnitude1 = math.sqrt(sum(a * a for a in vec1))\n",
    "        magnitude2 = math.sqrt(sum(a * a for a in vec2))\n",
    "        \n",
    "        if magnitude1 == 0 or magnitude2 == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        cosine_sim = dot_product / (magnitude1 * magnitude2)\n",
    "        \n",
    "        return cosine_sim\n",
    "    \n",
    "    def generate_distractors(self, correct_answer, context, num_distractors=3):\n",
    "        \"\"\"Generate distractors using cosine similarity and context analysis\"\"\"\n",
    "        distractors = []\n",
    "        \n",
    "        # Extract keywords and entities from context\n",
    "        keywords = self.extract_keywords(context, top_n=30)\n",
    "        entities = self.extract_named_entities(context)\n",
    "        \n",
    "        # Combine potential distractors\n",
    "        candidates = keywords + entities\n",
    "        \n",
    "        # Remove the correct answer from candidates\n",
    "        candidates = [c for c in candidates if c.lower() != correct_answer.lower()]\n",
    "        \n",
    "        # Score candidates based on similarity to context but dissimilarity to correct answer\n",
    "        scored_candidates = []\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            # Calculate similarity to context\n",
    "            context_sim = self.calculate_cosine_similarity(candidate, context)\n",
    "            \n",
    "            # Calculate similarity to correct answer (we want this to be low)\n",
    "            answer_sim = self.calculate_cosine_similarity(candidate, correct_answer)\n",
    "            \n",
    "            # Score: high context similarity, low answer similarity\n",
    "            score = context_sim - (answer_sim * 0.5)\n",
    "            \n",
    "            scored_candidates.append((candidate, score))\n",
    "        \n",
    "        # Sort by score and take top candidates\n",
    "        scored_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select distractors\n",
    "        for candidate, score in scored_candidates:\n",
    "            if len(distractors) >= num_distractors:\n",
    "                break\n",
    "            \n",
    "            # Avoid very similar distractors\n",
    "            is_similar = False\n",
    "            for existing in distractors:\n",
    "                if self.calculate_cosine_similarity(candidate, existing) > 0.7:\n",
    "                    is_similar = True\n",
    "                    break\n",
    "            \n",
    "            if not is_similar:\n",
    "                distractors.append(candidate)\n",
    "        \n",
    "        # If we don't have enough distractors, generate some generic ones\n",
    "        while len(distractors) < num_distractors:\n",
    "            generic_options = [\n",
    "                \"None of the above\",\n",
    "                \"All of the above\",\n",
    "                \"Cannot be determined\",\n",
    "                \"Not mentioned in the text\"\n",
    "            ]\n",
    "            \n",
    "            for option in generic_options:\n",
    "                if option not in distractors and len(distractors) < num_distractors:\n",
    "                    distractors.append(option)\n",
    "        \n",
    "        return distractors[:num_distractors]\n",
    "    \n",
    "    def generate_question_from_sentence(self, sentence, context):\n",
    "        \"\"\"Generate a question from a sentence\"\"\"\n",
    "        # Extract key information from sentence\n",
    "        words = word_tokenize(sentence)\n",
    "        pos_tags = pos_tag(words)\n",
    "        \n",
    "        # Find important nouns and entities\n",
    "        important_terms = []\n",
    "        for word, tag in pos_tags:\n",
    "            if tag in ['NN', 'NNS', 'NNP', 'NNPS'] and word.lower() not in self.stop_words:\n",
    "                important_terms.append(word)\n",
    "        \n",
    "        if not important_terms:\n",
    "            return None\n",
    "        \n",
    "        # Select the most important term as the answer\n",
    "        # Use TF-IDF to find the most important term in this sentence\n",
    "        term_scores = {}\n",
    "        for term in important_terms:\n",
    "            # Simple scoring based on position and frequency\n",
    "            position_score = 1.0 - (words.index(term) / len(words))  # Earlier terms get higher scores\n",
    "            frequency_score = context.lower().count(term.lower()) / len(context.split())\n",
    "            term_scores[term] = position_score + frequency_score\n",
    "        \n",
    "        if not term_scores:\n",
    "            return None\n",
    "        \n",
    "        # Get the best term as correct answer\n",
    "        correct_answer = max(term_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Generate question by replacing the answer with a blank or question word\n",
    "        question_sentence = sentence.replace(correct_answer, \"______\")\n",
    "        \n",
    "        # If replacement didn't work well, create a more structured question\n",
    "        if question_sentence == sentence:\n",
    "            # Try different question patterns\n",
    "            patterns = [\n",
    "                f\"What is mentioned as {correct_answer} in the text?\",\n",
    "                f\"According to the text, what refers to {correct_answer}?\",\n",
    "                f\"Which term is described as {correct_answer}?\"\n",
    "            ]\n",
    "            question_sentence = random.choice(patterns)\n",
    "        \n",
    "        # Generate distractors\n",
    "        distractors = self.generate_distractors(correct_answer, context)\n",
    "        \n",
    "        return {\n",
    "            'question': question_sentence,\n",
    "            'correct_answer': correct_answer,\n",
    "            'distractors': distractors,\n",
    "            'source_sentence': sentence\n",
    "        }\n",
    "    \n",
    "    def generate_mcqs(self, text, num_questions=5):\n",
    "        \"\"\"Generate multiple choice questions from text\"\"\"\n",
    "        print(\"Starting MCQ generation...\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        text = self.preprocess_text(text)\n",
    "        \n",
    "        # Extract sentences\n",
    "        sentences = self.extract_sentences(text)\n",
    "        \n",
    "        if len(sentences) < num_questions:\n",
    "            print(f\"Warning: Only {len(sentences)} sentences available for {num_questions} questions\")\n",
    "            num_questions = len(sentences)\n",
    "        \n",
    "        # Select diverse sentences for questions\n",
    "        selected_sentences = self.select_diverse_sentences(sentences, num_questions)\n",
    "        \n",
    "        mcqs = []\n",
    "        \n",
    "        for i, sentence in enumerate(selected_sentences):\n",
    "            print(f\"Generating question {i+1}/{num_questions}...\")\n",
    "            \n",
    "            mcq = self.generate_question_from_sentence(sentence, text)\n",
    "            \n",
    "            if mcq:\n",
    "                # Format the MCQ\n",
    "                options = [mcq['correct_answer']] + mcq['distractors']\n",
    "                random.shuffle(options)\n",
    "                \n",
    "                # Find correct answer index\n",
    "                correct_index = options.index(mcq['correct_answer'])\n",
    "                correct_letter = chr(65 + correct_index)  # A, B, C, D\n",
    "                \n",
    "                formatted_mcq = {\n",
    "                    'id': i + 1,\n",
    "                    'question': mcq['question'],\n",
    "                    'options': {\n",
    "                        'A': options[0],\n",
    "                        'B': options[1],\n",
    "                        'C': options[2] if len(options) > 2 else \"None of the above\",\n",
    "                        'D': options[3] if len(options) > 3 else \"All of the above\"\n",
    "                    },\n",
    "                    'correct_answer': correct_letter,\n",
    "                    'explanation': f\"Based on: {mcq['source_sentence']}\"\n",
    "                }\n",
    "                \n",
    "                mcqs.append(formatted_mcq)\n",
    "        \n",
    "        print(f\"Generated {len(mcqs)} MCQs successfully!\")\n",
    "        return mcqs\n",
    "    \n",
    "    def select_diverse_sentences(self, sentences, num_questions):\n",
    "        \"\"\"Select diverse sentences to avoid similar questions\"\"\"\n",
    "        if len(sentences) <= num_questions:\n",
    "            return sentences\n",
    "        \n",
    "        selected = []\n",
    "        remaining = sentences.copy()\n",
    "        \n",
    "        # Select first sentence randomly\n",
    "        first_sentence = random.choice(remaining)\n",
    "        selected.append(first_sentence)\n",
    "        remaining.remove(first_sentence)\n",
    "        \n",
    "        # Select remaining sentences based on diversity\n",
    "        while len(selected) < num_questions and remaining:\n",
    "            best_sentence = None\n",
    "            best_score = -1\n",
    "            \n",
    "            for sentence in remaining:\n",
    "                # Calculate average similarity to already selected sentences\n",
    "                similarities = []\n",
    "                for selected_sentence in selected:\n",
    "                    sim = self.calculate_cosine_similarity(sentence, selected_sentence)\n",
    "                    similarities.append(sim)\n",
    "                \n",
    "                # We want low similarity (high diversity)\n",
    "                avg_similarity = sum(similarities) / len(similarities)\n",
    "                diversity_score = 1 - avg_similarity\n",
    "                \n",
    "                if diversity_score > best_score:\n",
    "                    best_score = diversity_score\n",
    "                    best_sentence = sentence\n",
    "            \n",
    "            if best_sentence:\n",
    "                selected.append(best_sentence)\n",
    "                remaining.remove(best_sentence)\n",
    "        \n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf84009-0ac7-4e0a-8ada-161b80c45517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MCQ generation...\n",
      "Generating question 1/5...\n",
      "Generating question 2/5...\n",
      "Generating question 3/5...\n",
      "Generating question 4/5...\n",
      "Generating question 5/5...\n",
      "Generated 5 MCQs successfully!\n",
      "\n",
      "==================================================\n",
      "GENERATED MCQs\n",
      "==================================================\n",
      "\n",
      "Question 1: ______ learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions.\n",
      "----------------------------------------\n",
      "  A. learning\n",
      "✓ B. Reinforcement\n",
      "  C. computer\n",
      "  D. ai\n",
      "\n",
      "Correct Answer: B\n",
      "Explanation: Based on: Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 2: Natural ______ Processing NLP is a field of AI that focuses on the interaction between computers and human language.\n",
      "----------------------------------------\n",
      "  A. ai\n",
      "✓ B. Language\n",
      "  C. learning\n",
      "  D. computer\n",
      "\n",
      "Correct Answer: B\n",
      "Explanation: Based on: Natural Language Processing NLP is a field of AI that focuses on the interaction between computers and human language.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 3: The ______ Test, proposed by Alan ______ in 1950, is a test of a machines ability to exhibit intelligent behavior equivalent to human intelligence.\n",
      "----------------------------------------\n",
      "  A. learning\n",
      "✓ B. Turing\n",
      "  C. computer\n",
      "  D. ai\n",
      "\n",
      "Correct Answer: B\n",
      "Explanation: Based on: The Turing Test, proposed by Alan Turing in 1950, is a test of a machines ability to exhibit intelligent behavior equivalent to human intelligence.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 4: Unsupervised learning ______ finding patterns in data without labeled examples.\n",
      "----------------------------------------\n",
      "  A. ai\n",
      "  B. computer\n",
      "✓ C. involves\n",
      "  D. learning\n",
      "\n",
      "Correct Answer: C\n",
      "Explanation: Based on: Unsupervised learning involves finding patterns in data without labeled examples.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 5: ______ combines AI with mechanical engineering to create autonomous machines that can perform tasks in the physical world.\n",
      "----------------------------------------\n",
      "  A. computer\n",
      "  B. ai\n",
      "  C. learning\n",
      "✓ D. Robotics\n",
      "\n",
      "Correct Answer: D\n",
      "Explanation: Based on: Robotics combines AI with mechanical engineering to create autonomous machines that can perform tasks in the physical world.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Example usage\n",
    "    sample_text = \"\"\"\n",
    "    Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines. \n",
    "    Machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. \n",
    "    Deep learning is a subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns. \n",
    "    Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Computer vision is another important area of AI that enables machines to interpret and understand visual information from the world. \n",
    "    Robotics combines AI with mechanical engineering to create autonomous machines that can perform tasks in the physical world. \n",
    "    The Turing Test, proposed by Alan Turing in 1950, is a test of a machine's ability to exhibit intelligent behavior equivalent to human intelligence. \n",
    "    Supervised learning is a type of machine learning where algorithms learn from labeled training data. \n",
    "    Unsupervised learning involves finding patterns in data without labeled examples. \n",
    "    Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = MCQGenerator()\n",
    "    \n",
    "    # Generate MCQs\n",
    "    mcqs = generator.generate_mcqs(sample_text, num_questions=5)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GENERATED MCQs\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for mcq in mcqs:\n",
    "        print(f\"\\nQuestion {mcq['id']}: {mcq['question']}\")\n",
    "        print(\"-\" * 40)\n",
    "        for option_key, option_value in mcq['options'].items():\n",
    "            marker = \"✓\" if option_key == mcq['correct_answer'] else \" \"\n",
    "            print(f\"{marker} {option_key}. {option_value}\")\n",
    "        print(f\"\\nCorrect Answer: {mcq['correct_answer']}\")\n",
    "        print(f\"Explanation: {mcq['explanation']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823f4f5c-1a17-48b2-85b0-55ece0c8e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting improved MCQ generation...\n",
      "Generating question 1/5 for concept: consist\n",
      "Generating question 2/5 for concept: systems\n",
      "Generating question 3/5 for concept: Reinforcement learning\n",
      "Generating question 4/5 for concept: physical tasks\n",
      "Generating question 5/5 for concept: world\n",
      "Generated 5 improved MCQs successfully!\n",
      "\n",
      "============================================================\n",
      "IMPROVED MCQs - CONCEPTUAL QUESTIONS\n",
      "============================================================\n",
      "\n",
      "Question 1 [DEFINITION]: consist is primarily known for which of the following?\n",
      "Concept: consist\n",
      "--------------------------------------------------\n",
      "  A. Artificial Intelligence AI is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence.\n",
      "  B. a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence\n",
      "  C. A method used primarily for data storage and retrieval\n",
      "✓ D. Neural networks are computing systems inspired by biological neural networks that consist of interconnected nodes or neurons that process information.\n",
      "\n",
      "Correct Answer: D\n",
      "Explanation: Based on: Neural networks are computing systems inspired by biological neural networks that consist of interconnected nodes or neurons that process information.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question 2 [DEFINITION]: How can systems be best described?\n",
      "Concept: systems\n",
      "--------------------------------------------------\n",
      "✓ A. Neural networks are computing systems inspired by biological neural networks that consist of interconnected nodes or neurons that process information.\n",
      "  B. A method used primarily for data storage and retrieval\n",
      "  C. Artificial Intelligence AI is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence.\n",
      "  D. a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence\n",
      "\n",
      "Correct Answer: A\n",
      "Explanation: Based on: Neural networks are computing systems inspired by biological neural networks that consist of interconnected nodes or neurons that process information.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question 3 [DEFINITION]: What is the primary characteristic of Reinforcement learning?\n",
      "Concept: Reinforcement learning\n",
      "--------------------------------------------------\n",
      "  A. a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence\n",
      "  B. Artificial Intelligence AI is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence.\n",
      "  C. A method used primarily for data storage and retrieval\n",
      "✓ D. a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions in an environment\n",
      "\n",
      "Correct Answer: D\n",
      "Explanation: Based on: Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions in an environment.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question 4 [RELATIONSHIP]: What is the relationship between physical tasks and Turing Test?\n",
      "Concept: physical tasks\n",
      "--------------------------------------------------\n",
      "✓ A. Robotics combines AI with mechanical engineering to create autonomous machines that can perform physical tasks in the real world.\n",
      "  B. a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence\n",
      "  C. Artificial Intelligence AI is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence.\n",
      "  D. A specialized form of database management\n",
      "\n",
      "Correct Answer: A\n",
      "Explanation: Based on: Robotics combines AI with mechanical engineering to create autonomous machines that can perform physical tasks in the real world.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question 5 [DEFINITION]: What is the primary characteristic of world?\n",
      "Concept: world\n",
      "--------------------------------------------------\n",
      "  A. a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence\n",
      "  B. Artificial Intelligence AI is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence.\n",
      "✓ C. Computer vision is another important area of AI that enables machines to interpret and understand visual information from the world, such as images and videos.\n",
      "  D. A method used primarily for data storage and retrieval\n",
      "\n",
      "Correct Answer: C\n",
      "Explanation: Based on: Computer vision is another important area of AI that enables machines to interpret and understand visual information from the world, such as images and videos.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import string\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "class ImprovedMCQGenerator:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Enhanced question templates for different types of understanding\n",
    "        self.question_templates = {\n",
    "            'definition': [\n",
    "                \"Which of the following best defines {}?\",\n",
    "                \"What is the primary characteristic of {}?\",\n",
    "                \"How can {} be best described?\",\n",
    "                \"{} is primarily known for which of the following?\"\n",
    "            ],\n",
    "            'relationship': [\n",
    "                \"What is the relationship between {} and {}?\",\n",
    "                \"How does {} relate to {}?\",\n",
    "                \"Which statement best describes the connection between {} and {}?\"\n",
    "            ],\n",
    "            'purpose': [\n",
    "                \"What is the main purpose of {}?\",\n",
    "                \"Why is {} important?\",\n",
    "                \"What does {} aim to achieve?\",\n",
    "                \"The primary goal of {} is to:\"\n",
    "            ],\n",
    "            'comparison': [\n",
    "                \"What distinguishes {} from other similar concepts?\",\n",
    "                \"Which feature is unique to {}?\",\n",
    "                \"How does {} differ from related concepts?\"\n",
    "            ],\n",
    "            'application': [\n",
    "                \"In which scenario would {} be most useful?\",\n",
    "                \"What is a practical application of {}?\",\n",
    "                \"Where is {} commonly used?\"\n",
    "            ],\n",
    "            'cause_effect': [\n",
    "                \"What is the result of {}?\",\n",
    "                \"What causes {}?\",\n",
    "                \"Which of the following is an effect of {}?\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Keywords that indicate different types of relationships\n",
    "        self.relationship_indicators = {\n",
    "            'is': 'definition',\n",
    "            'are': 'definition', \n",
    "            'means': 'definition',\n",
    "            'refers': 'definition',\n",
    "            'enables': 'purpose',\n",
    "            'allows': 'purpose',\n",
    "            'helps': 'purpose',\n",
    "            'aims': 'purpose',\n",
    "            'focuses': 'purpose',\n",
    "            'combines': 'relationship',\n",
    "            'includes': 'relationship',\n",
    "            'contains': 'relationship',\n",
    "            'uses': 'application',\n",
    "            'applies': 'application',\n",
    "            'involves': 'application',\n",
    "            'causes': 'cause_effect',\n",
    "            'results': 'cause_effect',\n",
    "            'leads': 'cause_effect'\n",
    "        }\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess the input text\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        text = re.sub(r'[^\\w\\s\\.\\!\\?\\,\\;\\:\\-$$$$]', '', text)\n",
    "        return text\n",
    "\n",
    "    def extract_sentences(self, text):\n",
    "        \"\"\"Extract meaningful sentences from text\"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        # Filter sentences that are likely to contain useful information\n",
    "        meaningful_sentences = []\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            if (len(words) >= 8 and len(words) <= 30 and  # Good length\n",
    "                any(indicator in sentence.lower() for indicator in self.relationship_indicators.keys()) and  # Contains relationship words\n",
    "                not sentence.startswith(('However', 'Moreover', 'Furthermore', 'Additionally'))):  # Not just connective sentences\n",
    "                meaningful_sentences.append(sentence)\n",
    "        \n",
    "        return meaningful_sentences\n",
    "\n",
    "    def extract_key_concepts(self, text):\n",
    "        \"\"\"Extract key concepts and their contexts\"\"\"\n",
    "        sentences = self.extract_sentences(text)\n",
    "        concepts = {}\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            pos_tags = pos_tag(words)\n",
    "            \n",
    "            # Find noun phrases and proper nouns\n",
    "            current_phrase = []\n",
    "            for word, tag in pos_tags:\n",
    "                if tag in ['NN', 'NNS', 'NNP', 'NNPS', 'JJ'] and word.lower() not in self.stop_words:\n",
    "                    current_phrase.append(word)\n",
    "                else:\n",
    "                    if len(current_phrase) >= 1:\n",
    "                        concept = ' '.join(current_phrase)\n",
    "                        if len(concept) > 2 and concept not in concepts:\n",
    "                            concepts[concept] = {\n",
    "                                'sentence': sentence,\n",
    "                                'context': self.get_concept_context(concept, sentence),\n",
    "                                'type': self.determine_question_type(sentence)\n",
    "                            }\n",
    "                    current_phrase = []\n",
    "            \n",
    "            # Don't forget the last phrase\n",
    "            if len(current_phrase) >= 1:\n",
    "                concept = ' '.join(current_phrase)\n",
    "                if len(concept) > 2 and concept not in concepts:\n",
    "                    concepts[concept] = {\n",
    "                        'sentence': sentence,\n",
    "                        'context': self.get_concept_context(concept, sentence),\n",
    "                        'type': self.determine_question_type(sentence)\n",
    "                    }\n",
    "        \n",
    "        return concepts\n",
    "\n",
    "    def get_concept_context(self, concept, sentence):\n",
    "        \"\"\"Extract the context/definition of a concept from its sentence\"\"\"\n",
    "        # Find what comes after the concept\n",
    "        concept_lower = concept.lower()\n",
    "        sentence_lower = sentence.lower()\n",
    "        \n",
    "        if concept_lower in sentence_lower:\n",
    "            concept_index = sentence_lower.find(concept_lower)\n",
    "            after_concept = sentence[concept_index + len(concept):].strip()\n",
    "            \n",
    "            # Look for definition patterns\n",
    "            definition_patterns = [\n",
    "                r'^[\\s,]*is\\s+(.+?)[\\.\\,\\;]',\n",
    "                r'^[\\s,]*are\\s+(.+?)[\\.\\,\\;]', \n",
    "                r'^[\\s,]*means\\s+(.+?)[\\.\\,\\;]',\n",
    "                r'^[\\s,]*refers\\s+to\\s+(.+?)[\\.\\,\\;]',\n",
    "                r'^[\\s,]*enables\\s+(.+?)[\\.\\,\\;]',\n",
    "                r'^[\\s,]*allows\\s+(.+?)[\\.\\,\\;]'\n",
    "            ]\n",
    "            \n",
    "            for pattern in definition_patterns:\n",
    "                match = re.search(pattern, after_concept, re.IGNORECASE)\n",
    "                if match:\n",
    "                    return match.group(1).strip()\n",
    "        \n",
    "        return sentence\n",
    "\n",
    "    def determine_question_type(self, sentence):\n",
    "        \"\"\"Determine the type of question based on sentence structure\"\"\"\n",
    "        sentence_lower = sentence.lower()\n",
    "        \n",
    "        for indicator, q_type in self.relationship_indicators.items():\n",
    "            if indicator in sentence_lower:\n",
    "                return q_type\n",
    "        \n",
    "        return 'definition'  # Default type\n",
    "\n",
    "    def generate_conceptual_question(self, concept, concept_data, all_concepts):\n",
    "        \"\"\"Generate a conceptual question about the concept\"\"\"\n",
    "        question_type = concept_data['type']\n",
    "        sentence = concept_data['sentence']\n",
    "        context = concept_data['context']\n",
    "        \n",
    "        # Select appropriate question template\n",
    "        if question_type in self.question_templates:\n",
    "            template = random.choice(self.question_templates[question_type])\n",
    "        else:\n",
    "            template = random.choice(self.question_templates['definition'])\n",
    "        \n",
    "        # Generate the question\n",
    "        if '{}' in template:\n",
    "            if template.count('{}') == 1:\n",
    "                question = template.format(concept)\n",
    "            else:\n",
    "                # For relationship questions, find another related concept\n",
    "                related_concepts = [c for c in all_concepts.keys() if c != concept]\n",
    "                if related_concepts:\n",
    "                    related = random.choice(related_concepts)\n",
    "                    question = template.format(concept, related)\n",
    "                else:\n",
    "                    question = self.question_templates['definition'][0].format(concept)\n",
    "        else:\n",
    "            question = template\n",
    "        \n",
    "        return question, context\n",
    "\n",
    "    def generate_smart_distractors(self, correct_answer, concept, all_concepts, question_type):\n",
    "        \"\"\"Generate intelligent distractors based on question type and context\"\"\"\n",
    "        distractors = []\n",
    "        \n",
    "        # Strategy 1: Use contexts from other concepts as distractors\n",
    "        other_concepts = {k: v for k, v in all_concepts.items() if k != concept}\n",
    "        \n",
    "        for other_concept, other_data in other_concepts.items():\n",
    "            if len(distractors) >= 2:\n",
    "                break\n",
    "            \n",
    "            other_context = other_data['context']\n",
    "            \n",
    "            # Make sure the distractor is different enough\n",
    "            if (other_context != correct_answer and \n",
    "                len(other_context.split()) >= 3 and\n",
    "                not self.is_too_similar(correct_answer, other_context)):\n",
    "                distractors.append(other_context)\n",
    "        \n",
    "        # Strategy 2: Generate plausible but incorrect statements\n",
    "        if len(distractors) < 3:\n",
    "            generic_distractors = self.generate_generic_distractors(concept, question_type)\n",
    "            for distractor in generic_distractors:\n",
    "                if len(distractors) >= 3:\n",
    "                    break\n",
    "                if distractor not in distractors:\n",
    "                    distractors.append(distractor)\n",
    "        \n",
    "        # Strategy 3: Modify the correct answer slightly\n",
    "        if len(distractors) < 3:\n",
    "            modified_answer = self.create_modified_answer(correct_answer)\n",
    "            if modified_answer and modified_answer not in distractors:\n",
    "                distractors.append(modified_answer)\n",
    "        \n",
    "        # Fill remaining slots with generic options\n",
    "        generic_options = [\n",
    "            \"None of the mentioned options\",\n",
    "            \"All of the above statements\",\n",
    "            \"Cannot be determined from the given information\",\n",
    "            \"Not explicitly mentioned in the text\"\n",
    "        ]\n",
    "        \n",
    "        while len(distractors) < 3:\n",
    "            for option in generic_options:\n",
    "                if option not in distractors and len(distractors) < 3:\n",
    "                    distractors.append(option)\n",
    "        \n",
    "        return distractors[:3]\n",
    "\n",
    "    def is_too_similar(self, text1, text2):\n",
    "        \"\"\"Check if two texts are too similar\"\"\"\n",
    "        words1 = set(word_tokenize(text1.lower()))\n",
    "        words2 = set(word_tokenize(text2.lower()))\n",
    "        \n",
    "        if not words1 or not words2:\n",
    "            return False\n",
    "        \n",
    "        intersection = words1.intersection(words2)\n",
    "        union = words1.union(words2)\n",
    "        \n",
    "        similarity = len(intersection) / len(union)\n",
    "        return similarity > 0.6\n",
    "\n",
    "    def generate_generic_distractors(self, concept, question_type):\n",
    "        \"\"\"Generate generic but plausible distractors\"\"\"\n",
    "        distractors = []\n",
    "        \n",
    "        if question_type == 'definition':\n",
    "            distractors = [\n",
    "                f\"A method used primarily for data storage and retrieval\",\n",
    "                f\"A technique that focuses on user interface design\",\n",
    "                f\"A process that handles network communication protocols\"\n",
    "            ]\n",
    "        elif question_type == 'purpose':\n",
    "            distractors = [\n",
    "                f\"To provide entertainment and gaming functionality\",\n",
    "                f\"To manage financial transactions and accounting\",\n",
    "                f\"To control hardware device operations\"\n",
    "            ]\n",
    "        elif question_type == 'application':\n",
    "            distractors = [\n",
    "                f\"In social media content creation\",\n",
    "                f\"In restaurant menu planning\", \n",
    "                f\"In automotive manufacturing\"\n",
    "            ]\n",
    "        else:\n",
    "            distractors = [\n",
    "                f\"A specialized form of database management\",\n",
    "                f\"An advanced networking protocol\",\n",
    "                f\"A user authentication mechanism\"\n",
    "            ]\n",
    "        \n",
    "        return distractors\n",
    "\n",
    "    def create_modified_answer(self, correct_answer):\n",
    "        \"\"\"Create a slightly modified version of the correct answer\"\"\"\n",
    "        words = correct_answer.split()\n",
    "        if len(words) < 3:\n",
    "            return None\n",
    "        \n",
    "        # Replace some words with similar but incorrect terms\n",
    "        replacements = {\n",
    "            'enables': 'requires',\n",
    "            'allows': 'prevents', \n",
    "            'creates': 'destroys',\n",
    "            'improves': 'reduces',\n",
    "            'increases': 'decreases',\n",
    "            'machine': 'human',\n",
    "            'automatic': 'manual',\n",
    "            'intelligent': 'simple',\n",
    "            'complex': 'basic',\n",
    "            'advanced': 'primitive'\n",
    "        }\n",
    "        \n",
    "        modified_words = []\n",
    "        for word in words:\n",
    "            word_lower = word.lower()\n",
    "            if word_lower in replacements:\n",
    "                modified_words.append(replacements[word_lower])\n",
    "            else:\n",
    "                modified_words.append(word)\n",
    "        \n",
    "        modified_answer = ' '.join(modified_words)\n",
    "        return modified_answer if modified_answer != correct_answer else None\n",
    "\n",
    "    def generate_mcqs(self, text, num_questions=5):\n",
    "        \"\"\"Generate improved MCQs from text\"\"\"\n",
    "        print(\"Starting improved MCQ generation...\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        text = self.preprocess_text(text)\n",
    "        \n",
    "        # Extract key concepts\n",
    "        concepts = self.extract_key_concepts(text)\n",
    "        \n",
    "        if len(concepts) < num_questions:\n",
    "            print(f\"Warning: Only {len(concepts)} concepts found for {num_questions} questions\")\n",
    "            num_questions = min(len(concepts), num_questions)\n",
    "        \n",
    "        # Select the most important concepts\n",
    "        concept_items = list(concepts.items())\n",
    "        selected_concepts = random.sample(concept_items, num_questions)\n",
    "        \n",
    "        mcqs = []\n",
    "        \n",
    "        for i, (concept, concept_data) in enumerate(selected_concepts):\n",
    "            print(f\"Generating question {i+1}/{num_questions} for concept: {concept}\")\n",
    "            \n",
    "            # Generate conceptual question\n",
    "            question, correct_answer = self.generate_conceptual_question(concept, concept_data, concepts)\n",
    "            \n",
    "            # Generate smart distractors\n",
    "            distractors = self.generate_smart_distractors(\n",
    "                correct_answer, concept, concepts, concept_data['type']\n",
    "            )\n",
    "            \n",
    "            # Format the MCQ\n",
    "            options = [correct_answer] + distractors\n",
    "            random.shuffle(options)\n",
    "            \n",
    "            # Find correct answer index\n",
    "            correct_index = options.index(correct_answer)\n",
    "            correct_letter = chr(65 + correct_index)  # A, B, C, D\n",
    "            \n",
    "            formatted_mcq = {\n",
    "                'id': i + 1,\n",
    "                'question': question,\n",
    "                'options': {\n",
    "                    'A': options[0],\n",
    "                    'B': options[1],\n",
    "                    'C': options[2] if len(options) > 2 else \"None of the above\",\n",
    "                    'D': options[3] if len(options) > 3 else \"All of the above\"\n",
    "                },\n",
    "                'correct_answer': correct_letter,\n",
    "                'explanation': f\"Based on: {concept_data['sentence']}\",\n",
    "                'concept': concept,\n",
    "                'question_type': concept_data['type']\n",
    "            }\n",
    "            \n",
    "            mcqs.append(formatted_mcq)\n",
    "        \n",
    "        print(f\"Generated {len(mcqs)} improved MCQs successfully!\")\n",
    "        return mcqs\n",
    "\n",
    "def main():\n",
    "    # Example usage with more detailed text\n",
    "    sample_text = \"\"\"\n",
    "    Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. \n",
    "    Machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed for every task. \n",
    "    Deep learning is a subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns in large amounts of data. \n",
    "    Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language. \n",
    "    Computer vision is another important area of AI that enables machines to interpret and understand visual information from the world, such as images and videos. \n",
    "    Robotics combines AI with mechanical engineering to create autonomous machines that can perform physical tasks in the real world. \n",
    "    The Turing Test, proposed by Alan Turing in 1950, is a test of a machine's ability to exhibit intelligent behavior equivalent to or indistinguishable from human intelligence. \n",
    "    Supervised learning is a type of machine learning where algorithms learn from labeled training data to make predictions on new, unseen data. \n",
    "    Unsupervised learning involves finding hidden patterns in data without labeled examples or predefined outcomes. \n",
    "    Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties for their actions in an environment.\n",
    "    Neural networks are computing systems inspired by biological neural networks that consist of interconnected nodes or neurons that process information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize improved generator\n",
    "    generator = ImprovedMCQGenerator()\n",
    "    \n",
    "    # Generate MCQs\n",
    "    mcqs = generator.generate_mcqs(sample_text, num_questions=5)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"IMPROVED MCQs - CONCEPTUAL QUESTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for mcq in mcqs:\n",
    "        print(f\"\\nQuestion {mcq['id']} [{mcq['question_type'].upper()}]: {mcq['question']}\")\n",
    "        print(f\"Concept: {mcq['concept']}\")\n",
    "        print(\"-\" * 50)\n",
    "        for option_key, option_value in mcq['options'].items():\n",
    "            marker = \"✓\" if option_key == mcq['correct_answer'] else \" \"\n",
    "            print(f\"{marker} {option_key}. {option_value}\")\n",
    "        print(f\"\\nCorrect Answer: {mcq['correct_answer']}\")\n",
    "        print(f\"Explanation: {mcq['explanation']}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaae615-9b88-45da-868d-541b0362e7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8194c4-9d7e-4468-be67-0d32b67d3b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
