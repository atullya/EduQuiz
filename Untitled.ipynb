{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ad948d-603f-46e4-96b0-349c56bb2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3898f61-52ea-4d0b-9d8c-a491d3f394e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square. Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. The villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\n",
    "Legend had it that anyone who tasted a Shakespear would gain a glimpse into their future. Curiosity\n",
    "spread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. Young Emma, a\n",
    "spirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\n",
    "One crisp autumn morning, she approached the tree, heart racing. With a deep breath, she plucked a\n",
    "Shakespear and took a bite. Instantly, a whirlwind of visions enveloped her. She saw herself standing on a\n",
    "grand stage, the applause of a thousand voices echoing in her ears. In another glimpse, she wandered\n",
    "through enchanted forests, her stories coming to life.\n",
    "Determined to fulfill these dreams, Emma spent every spare moment writing. The villagers, inspired by\n",
    "her passion, began sharing their own tales. The square buzzed with creativity, and soon, Eldermere\n",
    "became a hub of storytelling.\n",
    "As the seasons changed, Emma’s words took flight. She published her first book, a collection of\n",
    "enchanting stories, and it captured the hearts of many beyond Eldermere. The Shakespear tree\n",
    "continued to stand, its golden pears glimmering, a reminder that dreams, when nurtured, could blossom\n",
    "into reality.\n",
    "And so, in the embrace of magic and creativity, the legacy of the Shakespear lived on, inspiring\n",
    "generations to reach for their dreams.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb2ac7-d98f-4155-8c84-9b3135173df3",
   "metadata": {},
   "source": [
    "## Text Preprocessing Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671a5951-c738-4364-a43e-4ba7c91474be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"in the heart of the quaint village of eldermere, a mysterious tree stood tall in the town square. its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. the villagers affectionately named it the 'shakespear' tree, believing it held magical properties.\\nlegend had it that anyone who tasted a shakespear would gain a glimpse into their future. curiosity\\nspread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. young emma, a\\nspirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\\none crisp autumn morning, she approached the tree, heart racing. with a deep breath, she plucked a\\nshakespear and took a bite. instantly, a whirlwind of visions enveloped her. she saw herself standing on a\\ngrand stage, the applause of a thousand voices echoing in her ears. in another glimpse, she wandered\\nthrough enchanted forests, her stories coming to life.\\ndetermined to fulfill these dreams, emma spent every spare moment writing. the villagers, inspired by\\nher passion, began sharing their own tales. the square buzzed with creativity, and soon, eldermere\\nbecame a hub of storytelling.\\nas the seasons changed, emma’s words took flight. she published her first book, a collection of\\nenchanting stories, and it captured the hearts of many beyond eldermere. the shakespear tree\\ncontinued to stand, its golden pears glimmering, a reminder that dreams, when nurtured, could blossom\\ninto reality.\\nand so, in the embrace of magic and creativity, the legacy of the shakespear lived on, inspiring\\ngenerations to reach for their dreams.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step1: lower casing text\n",
    "lower_text=text.lower()\n",
    "lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abd8cf-1ea9-4429-81be-403799517ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove punctuion, emoji blalba we mostly use RE(ReqularExpression)\n",
    "import re\n",
    "# re.findall(r\"\\w\",text_lower) \n",
    "re.findall(r\"[A-Za-z0-9]\",lower_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8eac5b-05c2-47ee-b1df-14f65f74d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intheheartofthequaintvillageofeldermereamysterioustreestoodtallinthetownsquareitsgnarledbranchesborefruitsthatresembledpearsbutwithanunusualtwisttheyseemedtoshimmerwithagoldenhuethevillagersaffectionatelynamedittheshakespeartreebelievingitheldmagicalpropertieslegendhaditthatanyonewhotastedashakespearwouldgainaglimpseintotheirfuturecuriosityspreadlikewildfireandsoonvillagersflockedtothetreeeagerforatasteofdestinyyoungemmaaspiritedgirlwithdreamsofbecomingawriterfeltanundeniablepulltowardtheshimmeringfruitonecrispautumnmorningsheapproachedthetreeheartracingwithadeepbreathshepluckedashakespearandtookabiteinstantlyawhirlwindofvisionsenvelopedhershesawherselfstandingonagrandstagetheapplauseofathousandvoicesechoinginherearsinanotherglimpseshewanderedthroughenchantedforestsherstoriescomingtolifedeterminedtofulfillthesedreamsemmaspenteverysparemomentwritingthevillagersinspiredbyherpassionbegansharingtheirowntalesthesquarebuzzedwithcreativityandsooneldermerebecameahubofstorytellingastheseasonschangedemmaswordstookflightshepublishedherfirstbookacollectionofenchantingstoriesanditcapturedtheheartsofmanybeyondeldermeretheshakespeartreecontinuedtostanditsgoldenpearsglimmeringareminderthatdreamswhennurturedcouldblossomintorealityandsointheembraceofmagicandcreativitythelegacyoftheshakespearlivedoninspiringgenerationstoreachfortheirdreams'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(re.findall(r\"[A-Za-z0-9]\",lower_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ec63fc-3c72-4d55-902e-e0c188a8916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the heart of the quaint village of eldermere a mysterious tree stood tall in the town square its gnarled branches bore fruits that resembled pears but with an unusual twist they seemed to shimmer with a golden hue the villagers affectionately named it the shakespear tree believing it held magical properties\\nlegend had it that anyone who tasted a shakespear would gain a glimpse into their future curiosity\\nspread like wildfire and soon villagers flocked to the tree eager for a taste of destiny young emma a\\nspirited girl with dreams of becoming a writer felt an undeniable pull toward the shimmering fruit\\none crisp autumn morning she approached the tree heart racing with a deep breath she plucked a\\nshakespear and took a bite instantly a whirlwind of visions enveloped her she saw herself standing on a\\ngrand stage the applause of a thousand voices echoing in her ears in another glimpse she wandered\\nthrough enchanted forests her stories coming to life\\ndetermined to fulfill these dreams emma spent every spare moment writing the villagers inspired by\\nher passion began sharing their own tales the square buzzed with creativity and soon eldermere\\nbecame a hub of storytelling\\nas the seasons changed emmas words took flight she published her first book a collection of\\nenchanting stories and it captured the hearts of many beyond eldermere the shakespear tree\\ncontinued to stand its golden pears glimmering a reminder that dreams when nurtured could blossom\\ninto reality\\nand so in the embrace of magic and creativity the legacy of the shakespear lived on inspiring\\ngenerations to reach for their dreams'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text=re.sub(r\"[^\\w\\s]\", \"\", lower_text)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b31571c-cd9f-487a-95b6-a66da6ff55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization: ['In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square.', 'Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue.', \"The villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\", 'Legend had it that anyone who tasted a Shakespear would gain a glimpse into their future.', 'Curiosity\\nspread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny.', 'Young Emma, a\\nspirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.', 'One crisp autumn morning, she approached the tree, heart racing.', 'With a deep breath, she plucked a\\nShakespear and took a bite.', 'Instantly, a whirlwind of visions enveloped her.', 'She saw herself standing on a\\ngrand stage, the applause of a thousand voices echoing in her ears.', 'In another glimpse, she wandered\\nthrough enchanted forests, her stories coming to life.', 'Determined to fulfill these dreams, Emma spent every spare moment writing.', 'The villagers, inspired by\\nher passion, began sharing their own tales.', 'The square buzzed with creativity, and soon, Eldermere\\nbecame a hub of storytelling.', 'As the seasons changed, Emma’s words took flight.', 'She published her first book, a collection of\\nenchanting stories, and it captured the hearts of many beyond Eldermere.', 'The Shakespear tree\\ncontinued to stand, its golden pears glimmering, a reminder that dreams, when nurtured, could blossom\\ninto reality.', 'And so, in the embrace of magic and creativity, the legacy of the Shakespear lived on, inspiring\\ngenerations to reach for their dreams.']\n"
     ]
    }
   ],
   "source": [
    "#Step2: Tokenization\n",
    "# Sentence tokenize\n",
    "sentences1 = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\", sentences1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b865778-0361-4362-8228-9e057be862db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenization: ['in', 'the', 'heart', 'of', 'the', 'quaint', 'village', 'of', 'eldermere', 'a', 'mysterious', 'tree', 'stood', 'tall', 'in', 'the', 'town', 'square', 'its', 'gnarled', 'branches', 'bore', 'fruits', 'that', 'resembled', 'pears', 'but', 'with', 'an', 'unusual', 'twist', 'they', 'seemed', 'to', 'shimmer', 'with', 'a', 'golden', 'hue', 'the', 'villagers', 'affectionately', 'named', 'it', 'the', 'shakespear', 'tree', 'believing', 'it', 'held', 'magical', 'properties', 'legend', 'had', 'it', 'that', 'anyone', 'who', 'tasted', 'a', 'shakespear', 'would', 'gain', 'a', 'glimpse', 'into', 'their', 'future', 'curiosity', 'spread', 'like', 'wildfire', 'and', 'soon', 'villagers', 'flocked', 'to', 'the', 'tree', 'eager', 'for', 'a', 'taste', 'of', 'destiny', 'young', 'emma', 'a', 'spirited', 'girl', 'with', 'dreams', 'of', 'becoming', 'a', 'writer', 'felt', 'an', 'undeniable', 'pull', 'toward', 'the', 'shimmering', 'fruit', 'one', 'crisp', 'autumn', 'morning', 'she', 'approached', 'the', 'tree', 'heart', 'racing', 'with', 'a', 'deep', 'breath', 'she', 'plucked', 'a', 'shakespear', 'and', 'took', 'a', 'bite', 'instantly', 'a', 'whirlwind', 'of', 'visions', 'enveloped', 'her', 'she', 'saw', 'herself', 'standing', 'on', 'a', 'grand', 'stage', 'the', 'applause', 'of', 'a', 'thousand', 'voices', 'echoing', 'in', 'her', 'ears', 'in', 'another', 'glimpse', 'she', 'wandered', 'through', 'enchanted', 'forests', 'her', 'stories', 'coming', 'to', 'life', 'determined', 'to', 'fulfill', 'these', 'dreams', 'emma', 'spent', 'every', 'spare', 'moment', 'writing', 'the', 'villagers', 'inspired', 'by', 'her', 'passion', 'began', 'sharing', 'their', 'own', 'tales', 'the', 'square', 'buzzed', 'with', 'creativity', 'and', 'soon', 'eldermere', 'became', 'a', 'hub', 'of', 'storytelling', 'as', 'the', 'seasons', 'changed', 'emmas', 'words', 'took', 'flight', 'she', 'published', 'her', 'first', 'book', 'a', 'collection', 'of', 'enchanting', 'stories', 'and', 'it', 'captured', 'the', 'hearts', 'of', 'many', 'beyond', 'eldermere', 'the', 'shakespear', 'tree', 'continued', 'to', 'stand', 'its', 'golden', 'pears', 'glimmering', 'a', 'reminder', 'that', 'dreams', 'when', 'nurtured', 'could', 'blossom', 'into', 'reality', 'and', 'so', 'in', 'the', 'embrace', 'of', 'magic', 'and', 'creativity', 'the', 'legacy', 'of', 'the', 'shakespear', 'lived', 'on', 'inspiring', 'generations', 'to', 'reach', 'for', 'their', 'dreams']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenize\n",
    "words = word_tokenize(clean_text)\n",
    "print(\"Word Tokenization:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50085d00-1532-4137-9a1a-af4b751beff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4644735c-6811-4cfb-968e-bd41948fba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step2: Removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bd9ecc0-2ab0-4b63-8a22-6d3168301fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48e75b-85ce-4653-bfed-14173dabdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "074d913e-32b2-4234-ac98-ca02b596640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2e97217-bcb0-4127-8f46-964a6e044d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f03da-e79f-4856-b01d-46c787997699",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82d0e50c-baec-4914-912e-e879434c79d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "Counter({'tree': 5, 'shakespear': 5, 'dream': 4, 'heart': 3, 'eldermere': 3, 'villager': 3, 'square': 2, 'fruit': 2, 'pear': 2, 'golden': 2, 'glimpse': 2, 'soon': 2, 'emma': 2, 'took': 2, 'story': 2, 'creativity': 2, 'quaint': 1, 'village': 1, 'mysterious': 1, 'stood': 1, 'tall': 1, 'town': 1, 'gnarled': 1, 'branch': 1, 'bore': 1, 'resembled': 1, 'unusual': 1, 'twist': 1, 'seemed': 1, 'shimmer': 1, 'hue': 1, 'affectionately': 1, 'named': 1, 'believing': 1, 'held': 1, 'magical': 1, 'property': 1, 'legend': 1, 'anyone': 1, 'tasted': 1, 'would': 1, 'gain': 1, 'future': 1, 'curiosity': 1, 'spread': 1, 'like': 1, 'wildfire': 1, 'flocked': 1, 'eager': 1, 'taste': 1, 'destiny': 1, 'young': 1, 'spirited': 1, 'girl': 1, 'becoming': 1, 'writer': 1, 'felt': 1, 'undeniable': 1, 'pull': 1, 'toward': 1, 'shimmering': 1, 'one': 1, 'crisp': 1, 'autumn': 1, 'morning': 1, 'approached': 1, 'racing': 1, 'deep': 1, 'breath': 1, 'plucked': 1, 'bite': 1, 'instantly': 1, 'whirlwind': 1, 'vision': 1, 'enveloped': 1, 'saw': 1, 'standing': 1, 'grand': 1, 'stage': 1, 'applause': 1, 'thousand': 1, 'voice': 1, 'echoing': 1, 'ear': 1, 'another': 1, 'wandered': 1, 'enchanted': 1, 'forest': 1, 'coming': 1, 'life': 1, 'determined': 1, 'fulfill': 1, 'spent': 1, 'every': 1, 'spare': 1, 'moment': 1, 'writing': 1, 'inspired': 1, 'passion': 1, 'began': 1, 'sharing': 1, 'tale': 1, 'buzzed': 1, 'became': 1, 'hub': 1, 'storytelling': 1, 'season': 1, 'changed': 1, 'emmas': 1, 'word': 1, 'flight': 1, 'published': 1, 'first': 1, 'book': 1, 'collection': 1, 'enchanting': 1, 'captured': 1, 'many': 1, 'beyond': 1, 'continued': 1, 'stand': 1, 'glimmering': 1, 'reminder': 1, 'nurtured': 1, 'could': 1, 'blossom': 1, 'reality': 1, 'embrace': 1, 'magic': 1, 'legacy': 1, 'lived': 1, 'inspiring': 1, 'generation': 1, 'reach': 1})\n",
      "['tree', 'shakespear', 'dream', 'heart', 'eldermere']\n"
     ]
    }
   ],
   "source": [
    "#Extracting keywords\n",
    "\n",
    "# lemmatized_tokens\n",
    "from collections import Counter\n",
    "# word_list=clean_text.split()\n",
    "word_list=lemmatized_tokens\n",
    "word_count=len(word_list)\n",
    "word_frequencies = Counter(word_list)\n",
    "print(word_count)\n",
    "print(word_frequencies)\n",
    "\n",
    "# e.g. top 5 keywords\n",
    "keywords1 = [word for word, freq in word_frequencies.most_common(5)]\n",
    "print(keywords1)\n",
    "# print(clean_text)\n",
    "# all_words = [w for w in clean_text]\n",
    "# word_freq = Counter(all_words)\n",
    "\n",
    "# all_words\n",
    "# word_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687ea1d-c4b5-42f8-a6c4-8897cc728a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF \n",
    "wordDict = dict.fromkeys(lemmatized_tokens, 0)\n",
    "for word in lemmatized_tokens:\n",
    "    wordDict[word] += 1\n",
    "wordDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8582f94a-1940-4235-8dfe-6603deedfa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "TF: {'heart': 0.018633540372670808, 'quaint': 0.006211180124223602, 'village': 0.006211180124223602, 'eldermere': 0.018633540372670808, 'mysterious': 0.006211180124223602, 'tree': 0.031055900621118012, 'stood': 0.006211180124223602, 'tall': 0.006211180124223602, 'town': 0.006211180124223602, 'square': 0.012422360248447204, 'gnarled': 0.006211180124223602, 'branch': 0.006211180124223602, 'bore': 0.006211180124223602, 'fruit': 0.012422360248447204, 'resembled': 0.006211180124223602, 'pear': 0.012422360248447204, 'unusual': 0.006211180124223602, 'twist': 0.006211180124223602, 'seemed': 0.006211180124223602, 'shimmer': 0.006211180124223602, 'golden': 0.012422360248447204, 'hue': 0.006211180124223602, 'villager': 0.018633540372670808, 'affectionately': 0.006211180124223602, 'named': 0.006211180124223602, 'shakespear': 0.031055900621118012, 'believing': 0.006211180124223602, 'held': 0.006211180124223602, 'magical': 0.006211180124223602, 'property': 0.006211180124223602, 'legend': 0.006211180124223602, 'anyone': 0.006211180124223602, 'tasted': 0.006211180124223602, 'would': 0.006211180124223602, 'gain': 0.006211180124223602, 'glimpse': 0.012422360248447204, 'future': 0.006211180124223602, 'curiosity': 0.006211180124223602, 'spread': 0.006211180124223602, 'like': 0.006211180124223602, 'wildfire': 0.006211180124223602, 'soon': 0.012422360248447204, 'flocked': 0.006211180124223602, 'eager': 0.006211180124223602, 'taste': 0.006211180124223602, 'destiny': 0.006211180124223602, 'young': 0.006211180124223602, 'emma': 0.012422360248447204, 'spirited': 0.006211180124223602, 'girl': 0.006211180124223602, 'dream': 0.024844720496894408, 'becoming': 0.006211180124223602, 'writer': 0.006211180124223602, 'felt': 0.006211180124223602, 'undeniable': 0.006211180124223602, 'pull': 0.006211180124223602, 'toward': 0.006211180124223602, 'shimmering': 0.006211180124223602, 'one': 0.006211180124223602, 'crisp': 0.006211180124223602, 'autumn': 0.006211180124223602, 'morning': 0.006211180124223602, 'approached': 0.006211180124223602, 'racing': 0.006211180124223602, 'deep': 0.006211180124223602, 'breath': 0.006211180124223602, 'plucked': 0.006211180124223602, 'took': 0.012422360248447204, 'bite': 0.006211180124223602, 'instantly': 0.006211180124223602, 'whirlwind': 0.006211180124223602, 'vision': 0.006211180124223602, 'enveloped': 0.006211180124223602, 'saw': 0.006211180124223602, 'standing': 0.006211180124223602, 'grand': 0.006211180124223602, 'stage': 0.006211180124223602, 'applause': 0.006211180124223602, 'thousand': 0.006211180124223602, 'voice': 0.006211180124223602, 'echoing': 0.006211180124223602, 'ear': 0.006211180124223602, 'another': 0.006211180124223602, 'wandered': 0.006211180124223602, 'enchanted': 0.006211180124223602, 'forest': 0.006211180124223602, 'story': 0.012422360248447204, 'coming': 0.006211180124223602, 'life': 0.006211180124223602, 'determined': 0.006211180124223602, 'fulfill': 0.006211180124223602, 'spent': 0.006211180124223602, 'every': 0.006211180124223602, 'spare': 0.006211180124223602, 'moment': 0.006211180124223602, 'writing': 0.006211180124223602, 'inspired': 0.006211180124223602, 'passion': 0.006211180124223602, 'began': 0.006211180124223602, 'sharing': 0.006211180124223602, 'tale': 0.006211180124223602, 'buzzed': 0.006211180124223602, 'creativity': 0.012422360248447204, 'became': 0.006211180124223602, 'hub': 0.006211180124223602, 'storytelling': 0.006211180124223602, 'season': 0.006211180124223602, 'changed': 0.006211180124223602, 'emmas': 0.006211180124223602, 'word': 0.006211180124223602, 'flight': 0.006211180124223602, 'published': 0.006211180124223602, 'first': 0.006211180124223602, 'book': 0.006211180124223602, 'collection': 0.006211180124223602, 'enchanting': 0.006211180124223602, 'captured': 0.006211180124223602, 'many': 0.006211180124223602, 'beyond': 0.006211180124223602, 'continued': 0.006211180124223602, 'stand': 0.006211180124223602, 'glimmering': 0.006211180124223602, 'reminder': 0.006211180124223602, 'nurtured': 0.006211180124223602, 'could': 0.006211180124223602, 'blossom': 0.006211180124223602, 'reality': 0.006211180124223602, 'embrace': 0.006211180124223602, 'magic': 0.006211180124223602, 'legacy': 0.006211180124223602, 'lived': 0.006211180124223602, 'inspiring': 0.006211180124223602, 'generation': 0.006211180124223602, 'reach': 0.006211180124223602}\n"
     ]
    }
   ],
   "source": [
    "def computeTF(wordDict):\n",
    "    tfDict = {}\n",
    "    bowcount = sum(wordDict.values())\n",
    "    print(bowcount)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bowcount)\n",
    "    return tfDict\n",
    "\n",
    "tfCalculate = computeTF(wordDict)\n",
    "print(\"TF:\", tfCalculate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae97a2a-362d-436d-a91f-fa76b45e3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfCalculate=computeTF(wordDict)\n",
    "tfCalculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c1a12-43db-4ae1-a597-dd406c193f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "docs = re.split(r'(?<=[.!?])\\s+', text)\n",
    "docList = []\n",
    "for doc in docs:\n",
    "    tokens = re.findall(r'\\w+', doc.lower())\n",
    "    print(tokens)\n",
    "    d = dict.fromkeys(tokens, 0)\n",
    "    for token in tokens:\n",
    "        d[token] += 1\n",
    "    docList.append(d)\n",
    "docList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d7912-f572-4166-96d6-378ea3406788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f0d2ad8-3508-4435-b89f-7c7c0fd9a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF: {'shimmering': 1.9777236052888476, 'anyone': 1.9777236052888476, 'every': 1.9777236052888476, 'villagers': 1.6766936096248666, 'herself': 1.9777236052888476, 'properties': 1.9777236052888476, 'determined': 1.9777236052888476, 'spread': 1.9777236052888476, 'instantly': 1.9777236052888476, 'shakespear': 1.5006023505691855, 'echoing': 1.9777236052888476, 'taste': 1.9777236052888476, 'reminder': 1.9777236052888476, 'for': 1.8016323462331665, 'legacy': 1.9777236052888476, 'bore': 1.9777236052888476, 'with': 1.5797835966168101, 'their': 1.6766936096248666, 'a': 1.1995723549052042, 'wandered': 1.9777236052888476, 'to': 1.4336555609385722, 'reach': 1.9777236052888476, 'writer': 1.9777236052888476, 'crisp': 1.9777236052888476, 'one': 1.9777236052888476, 'racing': 1.9777236052888476, 'they': 1.9777236052888476, 'flocked': 1.9777236052888476, 'these': 1.9777236052888476, 'voices': 1.9777236052888476, 'stand': 1.9777236052888476, 'like': 1.9777236052888476, 'passion': 1.9777236052888476, 'first': 1.9777236052888476, 'on': 1.8016323462331665, 'mysterious': 1.9777236052888476, 'affectionately': 1.9777236052888476, 'forests': 1.9777236052888476, 'so': 1.9777236052888476, 'town': 1.9777236052888476, 'but': 1.9777236052888476, 'undeniable': 1.9777236052888476, 'coming': 1.9777236052888476, 'that': 1.6766936096248666, 'girl': 1.9777236052888476, 'buzzed': 1.9777236052888476, 'destiny': 1.9777236052888476, 'autumn': 1.9777236052888476, 'an': 1.8016323462331665, 'fruit': 1.9777236052888476, 'captured': 1.9777236052888476, 'could': 1.9777236052888476, 'she': 1.5006023505691855, 'glimpse': 1.8016323462331665, 'and': 1.5006023505691855, 'approached': 1.9777236052888476, 'standing': 1.9777236052888476, 'embrace': 1.9777236052888476, 'whirlwind': 1.9777236052888476, 'lived': 1.9777236052888476, 'became': 1.9777236052888476, 'golden': 1.8016323462331665, 'seemed': 1.9777236052888476, 'ears': 1.9777236052888476, 'reality': 1.9777236052888476, 'eldermere': 1.6766936096248666, 'changed': 1.9777236052888476, 'twist': 1.9777236052888476, 'collection': 1.9777236052888476, 'spent': 1.9777236052888476, 'fruits': 1.9777236052888476, 'through': 1.9777236052888476, 'named': 1.9777236052888476, 'square': 1.8016323462331665, 'grand': 1.9777236052888476, 'saw': 1.9777236052888476, 'sharing': 1.9777236052888476, 'morning': 1.9777236052888476, 'believing': 1.9777236052888476, 'had': 1.9777236052888476, 'applause': 1.9777236052888476, 'fulfill': 1.9777236052888476, 'would': 1.9777236052888476, 'eager': 1.9777236052888476, 'dreams': 1.5797835966168101, 'many': 1.9777236052888476, 'young': 1.9777236052888476, 'took': 1.8016323462331665, 'generations': 1.9777236052888476, 'seasons': 1.9777236052888476, 'its': 1.8016323462331665, 'own': 1.9777236052888476, 'moment': 1.9777236052888476, 'tales': 1.9777236052888476, 'another': 1.9777236052888476, 'who': 1.9777236052888476, 'began': 1.9777236052888476, 'blossom': 1.9777236052888476, 'inspired': 1.9777236052888476, 'visions': 1.9777236052888476, 'becoming': 1.9777236052888476, 's': 1.9777236052888476, 'hub': 1.9777236052888476, 'beyond': 1.9777236052888476, 'storytelling': 1.9777236052888476, 'breath': 1.9777236052888476, 'gain': 1.9777236052888476, 'gnarled': 1.9777236052888476, 'of': 1.324511091513504, 'stage': 1.9777236052888476, 'her': 1.5006023505691855, 'published': 1.9777236052888476, 'toward': 1.9777236052888476, 'in': 1.5797835966168101, 'enchanted': 1.9777236052888476, 'enchanting': 1.9777236052888476, 'words': 1.9777236052888476, 'creativity': 1.8016323462331665, 'hue': 1.9777236052888476, 'wildfire': 1.9777236052888476, 'tall': 1.9777236052888476, 'writing': 1.9777236052888476, 'pears': 1.8016323462331665, 'into': 1.8016323462331665, 'spirited': 1.9777236052888476, 'stories': 1.8016323462331665, 'inspiring': 1.9777236052888476, 'thousand': 1.9777236052888476, 'magical': 1.9777236052888476, 'unusual': 1.9777236052888476, 'resembled': 1.9777236052888476, 'felt': 1.9777236052888476, 'book': 1.9777236052888476, 'it': 1.6766936096248666, 'hearts': 1.9777236052888476, 'tasted': 1.9777236052888476, 'deep': 1.9777236052888476, 'legend': 1.9777236052888476, 'quaint': 1.9777236052888476, 'heart': 1.8016323462331665, 'life': 1.9777236052888476, 'bite': 1.9777236052888476, 'when': 1.9777236052888476, 'enveloped': 1.9777236052888476, 'tree': 1.5006023505691855, 'emma': 1.6766936096248666, 'glimmering': 1.9777236052888476, 'the': 1.1648102486459921, 'as': 1.9777236052888476, 'by': 1.9777236052888476, 'stood': 1.9777236052888476, 'pull': 1.9777236052888476, 'magic': 1.9777236052888476, 'nurtured': 1.9777236052888476, 'village': 1.9777236052888476, 'spare': 1.9777236052888476, 'curiosity': 1.9777236052888476, 'future': 1.9777236052888476, 'plucked': 1.9777236052888476, 'continued': 1.9777236052888476, 'shimmer': 1.9777236052888476, 'soon': 1.8016323462331665, 'flight': 1.9777236052888476, 'branches': 1.9777236052888476, 'held': 1.9777236052888476}\n"
     ]
    }
   ],
   "source": [
    "#IDF calculation\n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    N = len(docList)\n",
    "    idfDict = {}\n",
    "    all_words = set(word for doc in docList for word in doc)\n",
    "    \n",
    "    for word in all_words:\n",
    "        containing_docs = sum(1 for doc in docList if word in doc)\n",
    "        idfDict[word] = math.log10((N + 1) / (containing_docs + 1)) + 1\n",
    "    return idfDict\n",
    "\n",
    "idfs = computeIDF(docList)\n",
    "print(\"IDF:\", idfs)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd8be0-a691-4118-8301-d7fd53249578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tf, idf):\n",
    "    tfidf = {}\n",
    "    for word, tfval in tf.items():\n",
    "        tfidf[word] = tfval * idf.get(word, 0)\n",
    "    return tfidf\n",
    "\n",
    "tfidf = computeTFIDF(tfCalculate, idfs)\n",
    "print(\"TF-IDF:\", tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ec3f022-98a2-4331-9f59-8d3ed2b2029e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tree', 'shakespear', 'heart', 'eldermere', 'fruit', 'square', 'golden', 'glimpse', 'soon', 'took']\n",
      "['in the heart of the quaint village of eldermere, a mysterious tree stood tall in the town square.', 'its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue.', \"the villagers affectionately named it the 'shakespear' tree, believing it held magical properties.\", 'legend had it that anyone who tasted a shakespear would gain a glimpse into their future.', 'curiosity\\nspread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny.', 'young emma, a\\nspirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.', 'one crisp autumn morning, she approached the tree, heart racing.', 'with a deep breath, she plucked a\\nshakespear and took a bite.', 'instantly, a whirlwind of visions enveloped her.', 'she saw herself standing on a\\ngrand stage, the applause of a thousand voices echoing in her ears.', 'in another glimpse, she wandered\\nthrough enchanted forests, her stories coming to life.', 'determined to fulfill these dreams, emma spent every spare moment writing.', 'the villagers, inspired by\\nher passion, began sharing their own tales.', 'the square buzzed with creativity, and soon, eldermere\\nbecame a hub of storytelling.', 'as the seasons changed, emma’s words took flight.', 'she published her first book, a collection of\\nenchanting stories, and it captured the hearts of many beyond eldermere.', 'the shakespear tree\\ncontinued to stand, its golden pears glimmering, a reminder that dreams, when nurtured, could blossom\\ninto reality.', 'and so, in the embrace of magic and creativity, the legacy of the shakespear lived on, inspiring\\ngenerations to reach for their dreams.']\n",
      "Q1: in the heart of the quaint village of eldermere, a mysterious _____ stood tall in the town square.\n",
      "   A. eldermere\n",
      "   B. tree\n",
      "   C. soon\n",
      "   D. heart\n",
      "Answer: tree\n",
      "\n",
      "Q2: the villagers affectionately named it the '_____' tree, believing it held magical properties.\n",
      "   A. shakespear\n",
      "   B. square\n",
      "   C. eldermere\n",
      "   D. glimpse\n",
      "Answer: shakespear\n",
      "\n",
      "Q3: in the _____ of the quaint village of eldermere, a mysterious tree stood tall in the town square.\n",
      "   A. took\n",
      "   B. golden\n",
      "   C. tree\n",
      "   D. heart\n",
      "Answer: heart\n",
      "\n",
      "Q4: in the heart of the quaint village of _____, a mysterious tree stood tall in the town square.\n",
      "   A. took\n",
      "   B. square\n",
      "   C. eldermere\n",
      "   D. heart\n",
      "Answer: eldermere\n",
      "\n",
      "Q5: its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue.\n",
      "   A. took\n",
      "   B. fruit\n",
      "   C. heart\n",
      "   D. golden\n",
      "Answer: fruit\n",
      "\n",
      "Q6: in the heart of the quaint village of eldermere, a mysterious tree stood tall in the town _____.\n",
      "   A. shakespear\n",
      "   B. golden\n",
      "   C. square\n",
      "   D. took\n",
      "Answer: square\n",
      "\n",
      "Q7: its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a _____ hue.\n",
      "   A. heart\n",
      "   B. eldermere\n",
      "   C. soon\n",
      "   D. golden\n",
      "Answer: golden\n",
      "\n",
      "Q8: legend had it that anyone who tasted a shakespear would gain a _____ into their future.\n",
      "   A. golden\n",
      "   B. shakespear\n",
      "   C. glimpse\n",
      "   D. heart\n",
      "Answer: glimpse\n",
      "\n",
      "Q9: curiosity\n",
      "spread like wildfire, and _____, villagers flocked to the tree, eager for a taste of destiny.\n",
      "   A. glimpse\n",
      "   B. shakespear\n",
      "   C. soon\n",
      "   D. fruit\n",
      "Answer: soon\n",
      "\n",
      "Q10: with a deep breath, she plucked a\n",
      "shakespear and _____ a bite.\n",
      "   A. glimpse\n",
      "   B. tree\n",
      "   C. took\n",
      "   D. soon\n",
      "Answer: took\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "# Example: tfidf_dict for the whole document or per sentence\n",
    "# Let's say: tfidf_scores = {'magic': 0.25, 'tree': 0.15, 'dreams': 0.12, 'village': 0.10, 'Emma': 0.09}\n",
    "\n",
    "# 1. Pick top N keywords\n",
    "top_keywords = sorted(tfidf.items(), key=lambda x: x[1], reverse=True)\n",
    "top_keywords = [kw for kw, score in top_keywords[:10]]  # top 10 keywords\n",
    "print(top_keywords)\n",
    "# 2. Split text into sentences\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', lower_text)\n",
    "# print(sentences)\n",
    "mcqs = []\n",
    "\n",
    "for keyword in top_keywords:\n",
    "    for sentence in sentences:\n",
    "        if keyword.lower() in sentence.lower():\n",
    "            # Replace keyword with blank\n",
    "            pattern = re.compile(r'\\b' + re.escape(keyword) + r'\\b', re.IGNORECASE)\n",
    "            question = pattern.sub('_____', sentence)\n",
    "            \n",
    "            # Create distractors (simple approach: random other keywords)\n",
    "            distractors = [w for w in top_keywords if w != keyword]\n",
    "            options = random.sample(distractors, min(3, len(distractors))) + [keyword]\n",
    "            random.shuffle(options)\n",
    "            \n",
    "            mcqs.append({\n",
    "                'question': question,\n",
    "                'options': options,\n",
    "                'answer': keyword\n",
    "            })\n",
    "            break  # Only one MCQ per keyword\n",
    "\n",
    "# Print MCQs\n",
    "for i, mcq in enumerate(mcqs, 1):\n",
    "    print(f\"Q{i}: {mcq['question']}\")\n",
    "    for idx, option in enumerate(mcq['options']):\n",
    "        print(f\"   {chr(65+idx)}. {option}\")\n",
    "    print(f\"Answer: {mcq['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421b0d5-f1f4-4372-b945-39650c12a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6- Get distractor from WordNet. These distractors work on the basis of hypernym and hyponym explained in detail in the documentation.\n",
    "\n",
    "def getDistractors(syn,word):\n",
    "    dists=[]\n",
    "    word=word.lower()\n",
    "    actword=word\n",
    "    if len(word.split())>0: #Splits the word with underscores(_) instead of spaces if there are multiple words\n",
    "        word.replace(\" \",\"_\")\n",
    "    hypernym = syn.hypernyms() #Gets the hypernyms of the word\n",
    "    if len(hypernym)==0: #If there are no hypernyms for the current word, we simple return the empty list of distractors\n",
    "        return dists\n",
    "    for each in hypernym[0].hyponyms(): #Other wise we find the relevant hyponyms for the hypernyms\n",
    "        name=each.lemmas()[0].name()\n",
    "        if(name==actword):\n",
    "            continue\n",
    "        name=name.replace(\"_\",\" \")\n",
    "        name=\" \".join(w.capitalize() for w in name.split())\n",
    "        if name is not None and name not in dists: #If the word is not already present in the list and is different from he actial word\n",
    "            dists.append(name)\n",
    "    return dists\n",
    "#print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f2704-cdda-4181-929b-5748736e2ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b879363-7052-4d1a-8a57-2d8377132643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a1810-1af2-4625-93ec-11a1ffd02d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2d6a9-1d8c-496c-a2fa-2e02c1158e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b51a77-456c-423f-83eb-e5373bce8a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f056fe5-2d66-4580-949b-06d3edfbbbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4010768-273a-48e0-a812-6c8f3ebaf63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc21718-b51e-4b49-8de8-47cf86632f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85bc5f-7755-404c-ac73-3fe986395c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e544694-928c-4b18-a693-c31ebbca3a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b94eaf-68ce-4ff7-892b-348066ad68a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f064e47-5fd0-4a89-892e-909a69d94af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate MCQs\n",
    "mcqs = []\n",
    "for sent in sentences1:\n",
    "    sent_lower = sent.lower()\n",
    "    for keyword in keywords1:\n",
    "        if keyword in sent_lower:\n",
    "            question = re.sub(rf'\\b{keyword}\\b', '_____', sent, flags=re.IGNORECASE)\n",
    "            mcqs.append((question.strip(), keyword))\n",
    "            break  # Only one MCQ per sentence\n",
    "\n",
    "# Output MCQs\n",
    "for i, (q, ans) in enumerate(mcqs, 1):\n",
    "    print(f\"\\nQ{i}: {q}\\nAns: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c50c92b-df39-45f4-8468-ecf8f02ee4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb637ef-8f08-4c85-be33-dcfb2dc05819",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096e25c-c326-4118-9133-64e7f3bde081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e8a2b-8b37-483a-a560-4306e6301f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af0711-95cf-42f8-9f59-dae08c6a60c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd399d5-a8e0-44a0-91c0-a9985ff35f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ff395-9d46-44e5-b1b0-aaee00a0d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "# Your text\n",
    "text = \"\"\"In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square. Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. The villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\n",
    "Legend had it that anyone who tasted a Shakespear would gain a glimpse into their future. Curiosity\n",
    "spread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. Young Emma, a\n",
    "spirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\n",
    "One crisp autumn morning, she approached the tree, heart racing. With a deep breath, she plucked a\n",
    "Shakespear and took a bite. Instantly, a whirlwind of visions enveloped her. She saw herself standing on a\n",
    "grand stage, the applause of a thousand voices echoing in her ears. In another glimpse, she wandered\n",
    "through enchanted forests, her stories coming to life.\n",
    "Determined to fulfill these dreams, Emma spent every spare moment writing. The villagers, inspired by\n",
    "her passion, began sharing their own tales. The square buzzed with creativity, and soon, Eldermere\n",
    "became a hub of storytelling.\n",
    "As the seasons changed, Emma’s words took flight. She published her first book, a collection of\n",
    "enchanting stories, and it captured the hearts of many beyond Eldermere. The Shakespear tree\n",
    "continued to stand, its golden pears glimmering, a reminder that dreams, when nurtured, could blossom\n",
    "into reality.\n",
    "And so, in the embrace of magic and creativity, the legacy of the Shakespear lived on, inspiring\n",
    "generations to reach for their dreams.\"\"\"\n",
    "\n",
    "# 1️⃣ Split into documents (sentences)\n",
    "documents = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "# print(documents)\n",
    "# 2️⃣ Preprocess: tokenize each sentence\n",
    "tokenized_docs = []\n",
    "for doc in documents:\n",
    "    tokens = re.findall(r'\\w+', doc.lower())\n",
    "    tokenized_docs.append(tokens)\n",
    "tokenized_docs\n",
    "\n",
    "# # 3️⃣ Compute TF for each doc\n",
    "# tf_list = []\n",
    "# for tokens in tokenized_docs:\n",
    "#     tf = {}\n",
    "#     for word in tokens:\n",
    "#         tf[word] = tf.get(word, 0) + 1\n",
    "#     # normalize\n",
    "#     total_terms = len(tokens)\n",
    "#     for word in tf:\n",
    "#         tf[word] /= total_terms\n",
    "#     tf_list.append(tf)\n",
    "\n",
    "# # 4️⃣ Compute IDF\n",
    "# N = len(tokenized_docs)\n",
    "# idf = {}\n",
    "# all_words = set(word for doc in tokenized_docs for word in doc)\n",
    "\n",
    "# for word in all_words:\n",
    "#     containing_docs = sum(1 for doc in tokenized_docs if word in doc)\n",
    "#     idf[word] = math.log(N / (1 + containing_docs)) + 1  # add 1 to denominator to avoid div by zero\n",
    "\n",
    "# # 5️⃣ Compute TF-IDF\n",
    "# tfidf_list = []\n",
    "# for tf in tf_list:\n",
    "#     tfidf = {}\n",
    "#     for word in tf:\n",
    "#         tfidf[word] = tf[word] * idf[word]\n",
    "#     tfidf_list.append(tfidf)\n",
    "\n",
    "# # ✅ Print example output\n",
    "# for i, tfidf in enumerate(tfidf_list[:3]):  # show first 3 sentences\n",
    "#     print(f\"\\nSentence {i+1} TF-IDF:\")\n",
    "#     for word, score in sorted(tfidf.items(), key=lambda x: -x[1])[:5]:  # top 5 words\n",
    "#         print(f\"{word}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c79c8-270e-418e-af62-edd5956c81ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880810d5-f339-4c55-af36-c99f18d4b23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa254844-8287-4e29-b6e4-98cef0e0b890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens: ['heart', 'quaint', 'village', 'eldermere', 'mysterious', 'tree', 'stand', 'tall', 'town', 'square']\n",
      "Top keywords: ['tree', 'fruit', 'shimmer', 'villager', 'shakespear', 'taste', 'heart', 'quaint', 'village', 'eldermere']\n",
      "\n",
      "Q1: What is related to 'tree' in the story?\n",
      "  A. tree\n",
      "  B. pull\n",
      "  C. young\n",
      "  D. twist\n",
      "Answer: tree\n",
      "\n",
      "Q2: What is related to 'fruit' in the story?\n",
      "  A. fruit\n",
      "  B. twist\n",
      "  C. young\n",
      "  D. pull\n",
      "Answer: fruit\n",
      "\n",
      "Q3: What does 'shimmer' refer to in the text?\n",
      "  A. young\n",
      "  B. pull\n",
      "  C. twist\n",
      "  D. shimmer\n",
      "Answer: shimmer\n",
      "\n",
      "Q4: What is related to 'villager' in the story?\n",
      "  A. villager\n",
      "  B. twist\n",
      "  C. pull\n",
      "  D. young\n",
      "Answer: villager\n",
      "\n",
      "Q5: What does 'shakespear' refer to in the text?\n",
      "  A. twist\n",
      "  B. shakespear\n",
      "  C. young\n",
      "  D. pull\n",
      "Answer: shakespear\n",
      "\n",
      "Q6: What is related to 'taste' in the story?\n",
      "  A. taste\n",
      "  B. young\n",
      "  C. pull\n",
      "  D. twist\n",
      "Answer: taste\n",
      "\n",
      "Q7: What is related to 'heart' in the story?\n",
      "  A. twist\n",
      "  B. heart\n",
      "  C. young\n",
      "  D. pull\n",
      "Answer: heart\n",
      "\n",
      "Q8: What is related to 'quaint' in the story?\n",
      "  A. pull\n",
      "  B. twist\n",
      "  C. young\n",
      "  D. quaint\n",
      "Answer: quaint\n",
      "\n",
      "Q9: What is related to 'village' in the story?\n",
      "  A. village\n",
      "  B. pull\n",
      "  C. twist\n",
      "  D. young\n",
      "Answer: village\n",
      "\n",
      "Q10: What is special about Eldermere in the story?\n",
      "  A. pull\n",
      "  B. twist\n",
      "  C. young\n",
      "  D. eldermere\n",
      "Answer: eldermere\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required resources (first time only)\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square. \n",
    "Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. \n",
    "The villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\n",
    "Legend had it that anyone who tasted a Shakespear would gain a glimpse into their future. Curiosity\n",
    "spread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. Young Emma, a\n",
    "spirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\"\"\"\n",
    "\n",
    "# 1️⃣ Tokenize sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# 2️⃣ Preprocessing functions\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # default\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', t) for t in tokens]  # remove punctuation\n",
    "    tokens = [t for t in tokens if t and t not in stop_words]\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmas = [lemmatizer.lemmatize(t, get_wordnet_pos(p)) for t, p in pos_tags]\n",
    "    return lemmas, pos_tags\n",
    "\n",
    "all_tokens, pos_tags = preprocess(text)\n",
    "\n",
    "print(\"Sample tokens:\", all_tokens[:10])\n",
    "\n",
    "# 3️⃣ NER using NLTK chunker\n",
    "ner_data = []\n",
    "for sent in sentences:\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    chunks = nltk.ne_chunk(pos)\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entity = ' '.join(c[0] for c in chunk)\n",
    "            ner_data.append({\n",
    "                'entity': entity,\n",
    "                'label': chunk.label(),\n",
    "                'context': sent\n",
    "            })\n",
    "\n",
    "# 4️⃣ TF\n",
    "def compute_tf(tokens):\n",
    "    count = len(tokens)\n",
    "    freqs = Counter(tokens)\n",
    "    return {w: f / count for w, f in freqs.items()}\n",
    "\n",
    "tf = compute_tf(all_tokens)\n",
    "\n",
    "# 5️⃣ IDF\n",
    "def compute_idf(sentences):\n",
    "    N = len(sentences)\n",
    "    idf = {}\n",
    "    sentence_tokens = [set(preprocess(s)[0]) for s in sentences]\n",
    "    all_words = set().union(*sentence_tokens)\n",
    "    for word in all_words:\n",
    "        containing = sum(1 for s in sentence_tokens if word in s)\n",
    "        idf[word] = math.log((N + 1) / (containing + 1)) + 1\n",
    "    return idf\n",
    "\n",
    "idf = compute_idf(sentences)\n",
    "\n",
    "# 6️⃣ TF-IDF\n",
    "tfidf = {w: tf[w] * idf.get(w, 0) for w in tf}\n",
    "top_keywords = sorted(tfidf.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_keywords = [w for w, _ in top_keywords]\n",
    "\n",
    "print(\"Top keywords:\", top_keywords)\n",
    "\n",
    "# 7️⃣ Cosine similarity + vectorize\n",
    "vocab = list(set(all_tokens))\n",
    "\n",
    "def vectorize(word):\n",
    "    vec = np.zeros(len(vocab))\n",
    "    if word in vocab:\n",
    "        idx = vocab.index(word)\n",
    "        vec[idx] = tfidf.get(word, 0)\n",
    "    return vec\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    if np.linalg.norm(a) == 0 or np.linalg.norm(b) == 0:\n",
    "        return 0\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# 8️⃣ Generate MCQs\n",
    "mcqs = []\n",
    "for keyword in top_keywords:\n",
    "    kw_vec = vectorize(keyword)\n",
    "    sims = []\n",
    "    for word in vocab:\n",
    "        if word != keyword:\n",
    "            sim = cosine_sim(kw_vec, vectorize(word))\n",
    "            sims.append((word, sim))\n",
    "    distractors = [w for w, _ in sorted(sims, key=lambda x: x[1], reverse=True)[:3]]\n",
    "\n",
    "    # Create question\n",
    "    question = None\n",
    "    for ner in ner_data:\n",
    "        if keyword in ner['entity'].lower():\n",
    "            if ner['label'] == 'PERSON':\n",
    "                question = f\"Who is {ner['entity']} in the story?\"\n",
    "            elif ner['label'] in ['GPE', 'LOCATION']:\n",
    "                question = f\"What is special about {ner['entity']} in the story?\"\n",
    "            else:\n",
    "                question = f\"What does {ner['entity']} represent in the text?\"\n",
    "            break\n",
    "    if not question:\n",
    "        pos = next((p for w, p in pos_tags if w == keyword), 'NN')\n",
    "        if pos.startswith('N'):\n",
    "            question = f\"What is related to '{keyword}' in the story?\"\n",
    "        elif pos.startswith('V'):\n",
    "            question = f\"What action does '{keyword}' describe in the text?\"\n",
    "        else:\n",
    "            question = f\"What does '{keyword}' refer to in the text?\"\n",
    "\n",
    "    options = distractors + [keyword]\n",
    "    np.random.shuffle(options)\n",
    "\n",
    "    mcqs.append({\n",
    "        'question': question,\n",
    "        'options': options,\n",
    "        'answer': keyword\n",
    "    })\n",
    "\n",
    "# 9️⃣ Print MCQs\n",
    "for i, mcq in enumerate(mcqs, 1):\n",
    "    print(f\"\\nQ{i}: {mcq['question']}\")\n",
    "    for j, opt in enumerate(mcq['options']):\n",
    "        print(f\"  {chr(65 + j)}. {opt}\")\n",
    "    print(f\"Answer: {mcq['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ef99f-0d72-49b8-8e34-addffa7c2df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686282d-6be7-4344-9601-1a066b7a8047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a8257-44aa-474c-9bb6-f61c5a129f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34c404-759d-4e6b-9b78-fb0953ed3c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641259d4-707c-45a0-bedb-ce8eba6d6fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83111032-d3f1-408b-8503-36851a1df625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1: What is special about Eldermere in the story?\n",
      "  A. Eldermere\n",
      "  B. Emma\n",
      "Answer: Eldermere\n",
      "\n",
      "Q2: Who is Legend in the story?\n",
      "  A. Legend\n",
      "  B. Young\n",
      "  C. fable\n",
      "  D. caption\n",
      "Answer: Legend\n",
      "\n",
      "Q3: Who is Young in the story?\n",
      "  A. Whitney Moore Young Jr.\n",
      "  B. Young\n",
      "  C. offspring\n",
      "  D. Pres Young\n",
      "Answer: Young\n",
      "\n",
      "Q4: What is special about Emma in the story?\n",
      "  A. Eldermere\n",
      "  B. Emma\n",
      "Answer: Emma\n",
      "\n",
      "Q5: In the story, what is related to 'tree'?\n",
      "  A. shoetree\n",
      "  B. Sir Herbert Beerbohm Tree\n",
      "  C. tree\n",
      "  D. corner\n",
      "Answer: tree\n",
      "\n",
      "Q6: In the story, what is related to 'fruit'?\n",
      "  A. yield\n",
      "  B. quaint\n",
      "  C. fruit\n",
      "  D. tree\n",
      "Answer: fruit\n",
      "\n",
      "Q7: In the story, what is related to 'shimmer'?\n",
      "  A. tree\n",
      "  B. heart\n",
      "  C. play\n",
      "  D. shimmer\n",
      "Answer: shimmer\n",
      "\n",
      "Q8: In the story, what is related to 'villager'?\n",
      "  A. shakespear\n",
      "  B. quaint\n",
      "  C. villager\n",
      "  D. village\n",
      "Answer: villager\n",
      "\n",
      "Q9: In the story, what is related to 'shakespear'?\n",
      "  A. taste\n",
      "  B. tree\n",
      "  C. heart\n",
      "  D. shakespear\n",
      "Answer: shakespear\n",
      "\n",
      "Q10: In the story, what is related to 'taste'?\n",
      "  A. discernment\n",
      "  B. predilection\n",
      "  C. taste\n",
      "  D. gustatory perception\n",
      "Answer: taste\n",
      "\n",
      "Q11: In the story, what is related to 'heart'?\n",
      "  A. heart\n",
      "  B. sum\n",
      "  C. eye\n",
      "  D. essence\n",
      "Answer: heart\n",
      "\n",
      "Q12: In the story, what is related to 'quaint'?\n",
      "  A. quaint\n",
      "  B. olde worlde\n",
      "  C. shakespear\n",
      "  D. old-time\n",
      "Answer: quaint\n",
      "\n",
      "Q13: In the story, what is related to 'village'?\n",
      "  A. hamlet\n",
      "  B. small town\n",
      "  C. settlement\n",
      "  D. village\n",
      "Answer: village\n",
      "\n",
      "Q14: In the story, what is related to 'eldermere'?\n",
      "  A. heart\n",
      "  B. shakespear\n",
      "  C. taste\n",
      "  D. eldermere\n",
      "Answer: eldermere\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# The text\n",
    "text = \"\"\"In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square. \n",
    "Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. \n",
    "The villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\n",
    "Legend had it that anyone who tasted a Shakespear would gain a glimpse into their future. Curiosity\n",
    "spread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. Young Emma, a\n",
    "spirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\"\"\"\n",
    "\n",
    "# Preprocess\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t and t not in stop_words]\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmas = [lemmatizer.lemmatize(t, get_wordnet_pos(p)) for t, p in pos_tags]\n",
    "    return lemmas, pos_tags\n",
    "\n",
    "tokens, pos_tags = preprocess(text)\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# NER\n",
    "ner_data = []\n",
    "for sent in sentences:\n",
    "    chunks = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entity = ' '.join(c[0] for c in chunk)\n",
    "            ner_data.append({\n",
    "                'entity': entity,\n",
    "                'label': chunk.label(),\n",
    "                'context': sent\n",
    "            })\n",
    "\n",
    "# TF-IDF\n",
    "tf = Counter(tokens)\n",
    "tf = {w: tf[w]/len(tokens) for w in tf}\n",
    "\n",
    "def compute_idf(sentences):\n",
    "    N = len(sentences)\n",
    "    sentence_tokens = [set(preprocess(s)[0]) for s in sentences]\n",
    "    idf = {}\n",
    "    all_words = set().union(*sentence_tokens)\n",
    "    for word in all_words:\n",
    "        containing = sum(1 for s in sentence_tokens if word in s)\n",
    "        idf[word] = math.log((N + 1) / (containing + 1)) + 1\n",
    "    return idf\n",
    "\n",
    "idf = compute_idf(sentences)\n",
    "tfidf = {w: tf[w] * idf.get(w, 0) for w in tf}\n",
    "top_keywords = sorted(tfidf.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_keywords = [w for w, _ in top_keywords]\n",
    "\n",
    "# WordNet distractors\n",
    "def get_wordnet_distractors(word):\n",
    "    distractors = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            name = lemma.name().replace('_', ' ')\n",
    "            if name.lower() != word.lower():\n",
    "                distractors.add(name)\n",
    "    return list(distractors)\n",
    "\n",
    "# Generate MCQs\n",
    "mcqs = []\n",
    "for ner in ner_data:\n",
    "    entity = ner['entity']\n",
    "    label = ner['label']\n",
    "    context = ner['context']\n",
    "\n",
    "    if label == 'PERSON':\n",
    "        q = f\"Who is {entity} in the story?\"\n",
    "    elif label in ['GPE', 'LOCATION']:\n",
    "        q = f\"What is special about {entity} in the story?\"\n",
    "    else:\n",
    "        q = f\"What does {entity} represent in the story?\"\n",
    "\n",
    "    # Distractors: other entities of same type\n",
    "    distractors = [n['entity'] for n in ner_data if n['entity'] != entity and n['label'] == label]\n",
    "    if len(distractors) < 3:\n",
    "        # Add WordNet distractors\n",
    "        wn_distractors = get_wordnet_distractors(entity.split()[0].lower())\n",
    "        distractors += wn_distractors\n",
    "    distractors = list(set(distractors))[:3]\n",
    "\n",
    "    options = distractors + [entity]\n",
    "    random.shuffle(options)\n",
    "\n",
    "    mcqs.append({\n",
    "        'question': q,\n",
    "        'options': options,\n",
    "        'answer': entity\n",
    "    })\n",
    "\n",
    "# Add keyword-based MCQs\n",
    "for kw in top_keywords:\n",
    "    q = f\"In the story, what is related to '{kw}'?\"\n",
    "    distractors = get_wordnet_distractors(kw)\n",
    "    if len(distractors) < 3:\n",
    "        other_kws = [w for w in top_keywords if w != kw]\n",
    "        distractors += random.sample(other_kws, min(3 - len(distractors), len(other_kws)))\n",
    "    distractors = list(set(distractors))[:3]\n",
    "    options = distractors + [kw]\n",
    "    random.shuffle(options)\n",
    "\n",
    "    mcqs.append({\n",
    "        'question': q,\n",
    "        'options': options,\n",
    "        'answer': kw\n",
    "    })\n",
    "\n",
    "# Print MCQs\n",
    "for i, mcq in enumerate(mcqs, 1):\n",
    "    print(f\"\\nQ{i}: {mcq['question']}\")\n",
    "    for j, opt in enumerate(mcq['options']):\n",
    "        print(f\"  {chr(65 + j)}. {opt}\")\n",
    "    print(f\"Answer: {mcq['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50bd67-b9d3-44e6-859a-994a7b486099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac7b41-7750-4f62-901c-adc5c5d407c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27b989-0089-486c-95ca-60292953ae23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94dea560-7745-4c87-99a5-c0ff652410d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square. \\nIts gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. \\nThe villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\\nLegend had it that anyone who tasted a Shakespear would gain a glimpse into their future. Curiosity\\nspread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. Young Emma, a\\nspirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1- Import the text file/article that has to be used for MCQ generation\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3d56565-df09-46e7-877f-a5a895b59a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\atulm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d0ef14c-0ef0-4701-baab-47a580814050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yake in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.4.8)\n",
      "Requirement already satisfied: tabulate in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from yake) (0.9.0)\n",
      "Requirement already satisfied: click>=6.0 in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from yake) (8.1.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from yake) (2.2.6)\n",
      "Requirement already satisfied: segtok in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from yake) (1.5.11)\n",
      "Requirement already satisfied: networkx in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from yake) (3.4.2)\n",
      "Requirement already satisfied: jellyfish in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from yake) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click>=6.0->yake) (0.4.6)\n",
      "Requirement already satisfied: regex in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from segtok->yake) (2024.11.6)\n"
     ]
    }
   ],
   "source": [
    "#Step 2- Extract the important words(keywords) from the text article that can be used to create MCQ using PKE (Python Keyword Extraction)\n",
    "!pip install yake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba6b995e-7458-42f9-a382-17c55e077bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eldermere', 'square', 'tree', 'Shakespear', 'heart', 'quaint', 'village', 'mysterious', 'stood', 'tall', 'town', 'villagers', 'Emma', 'pears', 'twist', 'hue', 'gnarled', 'branches', 'bore', 'resembled', 'unusual', 'shimmer', 'golden', 'believing', 'properties']\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "\n",
    "def getImportantWords(art, top_n=25):\n",
    "    # Create a YAKE keyword extractor\n",
    "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=top_n)  \n",
    "    # lan=\"en\" = English language\n",
    "    # n=1 = extract unigrams (single-word keywords, similar to PROPN in pke)\n",
    "\n",
    "    # Extract keywords\n",
    "    keywords = kw_extractor.extract_keywords(art)\n",
    "\n",
    "    # Get just the words, not the scores\n",
    "    result = [kw for kw, score in keywords]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "text = \"\"\"\n",
    "In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town square. \\nIts gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue. \\nThe villagers affectionately named it the 'Shakespear' tree, believing it held magical properties.\\nLegend had it that anyone who tasted a Shakespear would gain a glimpse into their future. Curiosity\\nspread like wildfire, and soon, villagers flocked to the tree, eager for a taste of destiny. Young Emma, a\\nspirited girl with dreams of becoming a writer, felt an undeniable pull toward the shimmering fruit.\n",
    "\"\"\"\n",
    "impWords = getImportantWords(text)\n",
    "print(impWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4044ffbd-cea7-4d8d-8adf-70641e859249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3- Split the whole text article into an array/list of individual sentences. This will help us fetch the sentences related to the keywords easily\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def splitTextToSents(art):\n",
    "    s=[sent_tokenize(art)]\n",
    "    s=[y for x in s for y in x]\n",
    "    s=[sent.strip() for sent in s if len(sent)>15] #Removes all the sentences that have length less than 15 so that we can ensure that our questions have enough length for context\n",
    "    return s\n",
    "sents=splitTextToSents(text) #Achieve a well splitted set of sentences from the text article\n",
    "#print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fce454f-1dc6-4d9f-a208-28f4cc3cbc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flashtext in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.7)\n"
     ]
    }
   ],
   "source": [
    "#Step 4- Map the sentences which contain the keywords to the related keywords so that we can easily lookup the sentences related to the keywords\n",
    "!pip install flashtext\n",
    "from flashtext import KeywordProcessor\n",
    "def mapSents(impWords,sents):\n",
    "    processor=KeywordProcessor() #Using keyword processor as our processor for this task\n",
    "    keySents={}\n",
    "    for word in impWords:\n",
    "        keySents[word]=[]\n",
    "        processor.add_keyword(word) #Adds key word to the processor\n",
    "    for sent in sents:\n",
    "        found=processor.extract_keywords(sent) #Extract the keywords in the sentence\n",
    "        for each in found:\n",
    "            keySents[each].append(sent) #For each keyword found, map the sentence to the keyword\n",
    "    for key in keySents.keys():\n",
    "        temp=keySents[key]\n",
    "        temp=sorted(temp,key=len,reverse=True) #Sort the sentences according to their decreasing length in order to ensure the quality of question for the MCQ \n",
    "        keySents[key]=temp\n",
    "    return keySents\n",
    "mappedSents=mapSents(impWords,sents) #Achieve the sentences that contain the keywords and map those sentences to the keywords using this function\n",
    "#print(mappedSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bc033a1-c45a-4bee-89ec-9f30b9f68364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pywsd in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.2.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pywsd) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pywsd) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pywsd) (2.2.3)\n",
      "Requirement already satisfied: wn==0.0.23 in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pywsd) (0.0.23)\n",
      "Requirement already satisfied: six in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pywsd) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk->pywsd) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk->pywsd) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk->pywsd) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk->pywsd) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click->nltk->pywsd) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->pywsd) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->pywsd) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\atulm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->pywsd) (2024.2)\n"
     ]
    }
   ],
   "source": [
    "#Step 5- Get the sense of the word. In order to attain a quality set of distractors we need to get the right sense of the keyword. This is explained in detail in the seperate alogrithm documentation\n",
    "!pip install pywsd\n",
    "from pywsd.similarity import max_similarity\n",
    "from pywsd.lesk import adapted_lesk\n",
    "from pywsd.lesk import simple_lesk\n",
    "from pywsd.lesk import cosine_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "def getWordSense(sent,word):\n",
    "    word=word.lower() \n",
    "    if len(word.split())>0: #Splits the word with underscores(_) instead of spaces if there are multiple words\n",
    "        word=word.replace(\" \",\"_\")\n",
    "    synsets=wn.synsets(word,'n') #Sysnets from Google are invoked\n",
    "    if synsets:\n",
    "        wup=max_similarity(sent,word,'wup',pos='n')\n",
    "        adapted_lesk_output = adapted_lesk(sent, word, pos='n')\n",
    "        lowest_index=min(synsets.index(wup),synsets.index(adapted_lesk_output))\n",
    "        return synsets[lowest_index]\n",
    "    else:\n",
    "        return None\n",
    "#print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "164b53a0-7c67-4e99-afee-81b4ec118377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7- The primary goal of this step is to take our MCQ quality one step further. The WordNet might some times fail to produce a hypernym for some words.\n",
    "#In that case the ConcepNet comes into play as they help achieve our distractors when there are no hypernyms present for it in the WordNet. More about this is discussed\n",
    "#in the algorithm documentation.\n",
    "\n",
    "import requests\n",
    "import json\n",
    "def getDistractors2(word):\n",
    "    word=word.lower()\n",
    "    actword=word\n",
    "    if len(word.split())>0: #Splits the word with underscores(_) instead of spaces if there are multiple words\n",
    "        word=word.replace(\" \",\"_\")\n",
    "    dists=[]\n",
    "    url= \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word) #To get ditractors from ConceptNet's API\n",
    "    obj=requests.get(url).json()\n",
    "    for edge in obj['edges']:\n",
    "        link=edge['end']['term']\n",
    "        url2=\"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
    "        obj2=requests.get(url2).json()\n",
    "        for edge in obj2['edges']:\n",
    "            word2=edge['start']['label']\n",
    "            if word2 not in dists and actword.lower() not in word2.lower(): #If the word is not already present in the list and is different from he actial word\n",
    "                dists.append(word2)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "736d4e25-56ea-4b33-8fa2-797c4ac04a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywsd.similarity import max_similarity\n",
    "from pywsd.lesk import adapted_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def getWordSense(sent, word):\n",
    "    synsets = wn.synsets(word, 'n')\n",
    "    if synsets:\n",
    "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
    "        adapted_lesk_output = adapted_lesk(sent, word, pos='n')\n",
    "        \n",
    "        # If max_similarity failed to find anything\n",
    "        if not wup:\n",
    "            if adapted_lesk_output:\n",
    "                return adapted_lesk_output\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        # If adapted_lesk_output failed\n",
    "        if not adapted_lesk_output:\n",
    "            return wup\n",
    "        \n",
    "        # Otherwise pick the one with lower index (you can customize this logic)\n",
    "        try:\n",
    "            lowest_index = min(synsets.index(wup), synsets.index(adapted_lesk_output))\n",
    "            return synsets[lowest_index]\n",
    "        except ValueError:\n",
    "            # One of the synsets wasn't found in the list\n",
    "            return wup or adapted_lesk_output\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26a9eadf-ecda-4cf4-a730-08deeda4599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************        Multiple Choice Questions        *******************************\n",
      "\n",
      "Question 1->  In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the town ________.\n",
      "\t a )  Square\n",
      "\t b )  Battlefield\n",
      "\t c )  Breeding Ground\n",
      "\t d )  Baseball Diamond\n",
      "\n",
      "Question 2->  Curiosity\n",
      "spread like wildfire, and soon, villagers flocked to the ________, eager for a taste of destiny.\n",
      "\t a )  Heart\n",
      "\t b )  Conic Section\n",
      "\t c )  Ellipsoid\n",
      "\t d )  Tree\n",
      "\n",
      "Question 3->  In the ________ of the quaint village of Eldermere, a mysterious tree stood tall in the town square.\n",
      "\t a )  Arena\n",
      "\t b )  Anchorage\n",
      "\t c )  Bed Ground\n",
      "\t d )  Heart\n",
      "\n",
      "Question 4->  In the heart of the quaint village of Eldermere, a mysterious tree stood ________ in the town square.\n",
      "\t a )  Tall\n",
      "\t b )  Extra Large\n",
      "\t c )  Large\n",
      "\t d )  Number\n",
      "\n",
      "Question 5->  In the heart of the quaint village of Eldermere, a mysterious tree stood tall in the ________ square.\n",
      "\t a )  Canton\n",
      "\t b )  Town\n",
      "\t c )  Borough\n",
      "\t d )  City\n",
      "\n",
      "Question 6->  Curiosity\n",
      "spread like wildfire, and soon, ________ flocked to the tree, eager for a taste of destiny.\n",
      "\t a )  Villagers\n",
      "\t b )  American\n",
      "\t c )  Alsatian\n",
      "\t d )  Asian\n",
      "\n",
      "Question 7->  Its gnarled branches bore fruits that resembled ________, but with an unusual twist: they seemed to shimmer with a golden hue.\n",
      "\t a )  Ackee\n",
      "\t b )  Anchovy Pear\n",
      "\t c )  Pears\n",
      "\t d )  Apple\n",
      "\n",
      "Question 8->  Its gnarled branches bore fruits that resembled pears, but with an unusual ________: they seemed to shimmer with a golden hue.\n",
      "\t a )  Twist\n",
      "\t b )  Bleeding\n",
      "\t c )  Birth Trauma\n",
      "\t d )  Blast Trauma\n",
      "\n",
      "Question 9->  Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden ________.\n",
      "\t a )  Paleness\n",
      "\t b )  Hue\n",
      "\t c )  Saturation\n",
      "\t d )  Value\n",
      "\n",
      "Question 10->  Its gnarled ________ bore fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue.\n",
      "\t a )  Branch\n",
      "\t b )  Facet\n",
      "\t c )  Branches\n",
      "\t d )  Flank\n",
      "\n",
      "Question 11->  Its gnarled branches ________ fruits that resembled pears, but with an unusual twist: they seemed to shimmer with a golden hue.\n",
      "\t a )  Tidal Bore\n",
      "\t b )  Bore\n",
      "\n",
      "Question 12->  Its gnarled branches bore fruits that resembled pears, but with an unusual twist: they seemed to ________ with a golden hue.\n",
      "\t a )  Acceleration\n",
      "\t b )  Shimmer\n",
      "\t c )  Avulsion\n",
      "\t d )  Birth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 9- The final step is to present our MCQ in a nice and readable manner.\n",
    "\n",
    "print(\"**************************************        Multiple Choice Questions        *******************************\")\n",
    "print()\n",
    "import re\n",
    "import random\n",
    "iterator = 1 #To keep the count of the questions\n",
    "for each in mappedDists:\n",
    "    sent=mappedSents[each][0]\n",
    "    p=re.compile(each,re.IGNORECASE) #Converts into regular expression for pattern matching\n",
    "    op=p.sub(\"________\",sent) #Replaces the keyword with underscores(blanks)\n",
    "    print(\"Question %s-> \"%(iterator),op) #Prints the question along with a question number\n",
    "    options=[each.capitalize()]+mappedDists[each] #Capitalizes the options\n",
    "    options=options[:4] #Selects only 4 options\n",
    "    opts=['a','b','c','d']\n",
    "    random.shuffle(options) #Shuffle the options so that order is not always same\n",
    "    for i,ch in enumerate(options):\n",
    "        print(\"\\t\",opts[i],\") \", ch) #Print the options\n",
    "    print()\n",
    "    iterator+=1 #Increase the counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a19203-2a28-47d5-ac24-53a683d67065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aacc05-78a6-431b-a3b9-b12774c46e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4651d-496b-4169-bbbf-8859dfbd4c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb4d84-e74a-48ca-988d-81be736e68bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bac95-7b1b-46b2-9dd5-91a0088d76fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65adee-a6b9-42d8-856d-663d906e31cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
